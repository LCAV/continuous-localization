{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Public dataset evaluation\n",
    "\n",
    "In this notebook we test and evaluabte publicly available datasets (see *datasets/* folder)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.io import loadmat\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from data_utils import *\n",
    "\n",
    "plt.rcParams['figure.figsize'] = 7, 3\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "matplotlib.rcParams['ps.fonttype'] = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains functionality to evaluate the proposed algorithms on real datasets. To simply reproduce the plots from the paper you can directly run GenerateAllFigures. \n",
    "\n",
    "# Preparation\n",
    "\n",
    "### 1. Download .mat files and save them in folder ./datasets/ (can simply run download_datasets.sh)\n",
    "\n",
    "WiFi: http://www.robesafe.es/repository/UAHWiFiDataset/\n",
    "\n",
    "Lawnmower: https://github.com/gtrll/gpslam/raw/master/matlab/data/\n",
    "\n",
    "See datasets/README.md for file description.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Choose dataset and range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trajectory_creator import get_trajectory\n",
    "\n",
    "anchor_names = None  # use all anchors by default.\n",
    "\n",
    "#filename = 'datasets/uah1.mat' # fingers\n",
    "#filename = 'datasets/Plaza1.mat'; # zig zag. \n",
    "filename = 'datasets/Plaza2.mat' # triangle\n",
    "\n",
    "verbose = False\n",
    "traj = get_trajectory(filename)\n",
    "dataname = filename.split('/')[-1].split('.')[0]\n",
    "\n",
    "if dataname == 'uah1':\n",
    "    t_window = 1.0\n",
    "    eps = 2.0\n",
    "    xlim = 0, 50\n",
    "    ylim = -20, 20\n",
    "\n",
    "    min_time = 0\n",
    "    max_time = 1000\n",
    "elif dataname == 'Plaza1':\n",
    "    t_window = 0.5\n",
    "    eps = 0.5\n",
    "    xlim = -50, 10\n",
    "    ylim = -20, 75\n",
    "\n",
    "    # choose one:\n",
    "    min_time = 0  # first big circle\n",
    "    max_time = 200  # first big circle\n",
    "    min_time = 510  # first loop\n",
    "    max_time = 600  # first loop\n",
    "    min_time = 0  # first few loops\n",
    "    max_time = 1000  # first few loops.\n",
    "elif dataname == 'Plaza2':\n",
    "    t_window = 0.1\n",
    "    eps = 0.2\n",
    "    xlim = -80, 10\n",
    "    ylim = -20, 75\n",
    "\n",
    "    min_time = 45.1\n",
    "    period = 101 - 45\n",
    "    print('period:', period)\n",
    "    num_loops = 2\n",
    "    max_time = min_time + num_loops * period\n",
    "    traj.period = period\n",
    "\n",
    "    #anchor_names = ['Range {}'.format(i) for i in range(1, 4)]\n",
    "try:\n",
    "    result_dict = loadmat(filename)\n",
    "except FileNotFoundError:\n",
    "    raise FileNotFoundError('Could not find {}. Did you run the script download_datasets?'.format(dataset))\n",
    "except Exception as e:\n",
    "    print('Unknown reading error with {}. Check if the file looks ok.'.format(filename))\n",
    "    raise e\n",
    "print('Successfully read {}'.format(filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_utils import prepare_dataset\n",
    "\n",
    "full_df, anchors_df = prepare_dataset(\n",
    "    result_dict, \n",
    "    range_system_id, \n",
    "    gt_system_id, \n",
    "    [min_time, max_time], \n",
    "    t_window)\n",
    "\n",
    "fig, axs = plt.subplots(1, 2)\n",
    "sns.scatterplot(data=full_df, x='px', y='py', hue='timestamp', linewidth=0.0, ax=axs[0])\n",
    "sns.scatterplot(data=full_df, x='timestamp', y='px', hue='timestamp', linewidth=0.0, ax=axs[1])\n",
    "sns.scatterplot(data=anchors_df, x='px', y='py', linewidth=0.0,  ax=axs[0], color='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. (optional) plot distance measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2)\n",
    "range_df = full_df.loc[full_df.system_id == range_system_id].copy()\n",
    "sns.scatterplot(data=range_df, x='px', y='py', hue='timestamp', linewidth=0.0, ax=axs[0])\n",
    "sns.scatterplot(data=anchors_df, x='px', y='py', linewidth=0.0,  ax=axs[0], color='red')\n",
    "for a_id, px, py in zip(anchors_df.anchor_id, anchors_df.px, anchors_df.py):\n",
    "    print(a_id, px, py)\n",
    "    axs[0].annotate(s='a{}'.format(a_id), xy=(px+2,py+2), color='red')\n",
    "axs[0].legend('')\n",
    "sns.scatterplot(data=range_df, x='timestamp', y='px', hue='timestamp', linewidth=0.0, ax=axs[1])\n",
    "\n",
    "plot_distance_times(full_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(5, 2)\n",
    "ax = plot_distance_errors(full_df, ax=ax)\n",
    "#savefig(fig, 'results/accuracy.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_names = sorted(range_df.anchor_name.unique())\n",
    "fig, axs = plt.subplots(1, len(anchor_names), sharey=True)\n",
    "fig.set_size_inches(15, 4)\n",
    "for ax, anchor_name in zip(axs, anchor_names):\n",
    "    plot_df = range_df.loc[range_df.anchor_name==anchor_name].copy()\n",
    "    plot_df.loc[:, 'distance error'] = plot_df.distance.values - plot_df.distance_gt.values\n",
    "    plot_df.loc[:, 'anchor name'] = plot_df.anchor_name.values\n",
    "    anchors_df.loc[:, 'anchor name'] = anchors_df.anchor_name.values\n",
    "    sns.scatterplot(data=plot_df, x='px', y='py', hue='anchor name', size='distance error', \n",
    "                    hue_order=anchor_names, linewidth=0.0, alpha=0.8, ax=ax, legend=False)\n",
    "    sns.scatterplot(data=anchors_df, x='px', y='py', hue='anchor name',\n",
    "                    hue_order=anchor_names, linewidth=0.0, legend=False, ax=ax)\n",
    "    ax.axis('equal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. (optional) Filter measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = full_df[full_df.distance<=50]\n",
    "\n",
    "plot_distance_times(filtered_df)\n",
    "ax = plot_distance_errors(filtered_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reconstruction\n",
    "\n",
    "### 1. Prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate_dataset import compute_distance_matrix\n",
    "\n",
    "chosen_df = full_df\n",
    "#chosen_df = filtered_df\n",
    "chosen_distance = 'distance'\n",
    "#chosen_distance = 'distance_gt'\n",
    "\n",
    "## Construct anchors. \n",
    "if anchor_names is None:\n",
    "    anchors = anchors_df.loc[:, ['px', 'py', 'pz']].values.astype(np.float32).T\n",
    "else:\n",
    "    anchors_df = anchors_df.loc[anchors_df.anchor_name.isin(anchor_names)]\n",
    "    anchors = get_coordinates(anchors_df, anchor_names)\n",
    "\n",
    "## Construct times.\n",
    "range_df = chosen_df[chosen_df.system_id == range_system_id]\n",
    "times = range_df.timestamp.unique()\n",
    "\n",
    "## Construct D.\n",
    "D, times = compute_distance_matrix(chosen_df, anchors_df, anchor_names, times, chosen_distance)\n",
    "if np.sum(D > 0) > D.shape[0]:\n",
    "    print('Warning: multiple measurements for times:{}/{}!'.format(\n",
    "          np.sum(np.sum(D > 0, axis=1)>1), D.shape[0]))\n",
    "\n",
    "## Construct ground truth.\n",
    "ground_truth_pos = get_ground_truth(chosen_df, times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Global algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from other_algorithms import pointwise_srls\n",
    "from plotting_tools import plot_complexities\n",
    "\n",
    "list_complexities = [3, 5, 21, 51]\n",
    "fig_size = [5, 1.2]\n",
    "ylim = [-15, 75]\n",
    "\n",
    "srls = True\n",
    "\n",
    "fig, axs = plot_complexities(traj, D, times, anchors, full_df, \n",
    "                             list_complexities, srls=srls)\n",
    "[ax.set_xlim(*xlim) for ax in axs]\n",
    "[ax.set_ylim(*ylim) for ax in axs]\n",
    "fig.set_size_inches(*fig_size) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotting_tools import plot_subsample\n",
    "\n",
    "n_complexity = 5\n",
    "traj.set_n_complexity(n_complexity)\n",
    "\n",
    "min_number = n_complexity*(traj.dim + 2) - 1 \n",
    "print(min_number, D.shape[0])\n",
    "#n_measurements_list = np.arange(D.shape[0], min_number, step=-100)\n",
    "#n_measurements_list = [19, 20, 30, 40, 50, 100, 200, 300, 499]\n",
    "n_measurements_list = [19, 30, 60, 200][::-1]\n",
    "\n",
    "fig, axs = plot_subsample(traj, D, times, anchors, full_df, \n",
    "                          n_measurements_list)\n",
    "[ax.set_xlim(*xlim) for ax in axs]\n",
    "[ax.set_ylim(*ylim) for ax in axs]\n",
    "fig.set_size_inches(*fig_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare with other algorithms\n",
    "\n",
    "This part is in beta-stage. We compare against other algorithms such as Lebenberg-Marquardt optimization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from measurements import get_measurements, add_noise, create_mask\n",
    "from other_algorithms import least_squares_lm, cost_function, calculate_error\n",
    "\n",
    "np.random.seed(2)    \n",
    "\n",
    "n_complexity = 5\n",
    "traj.set_n_complexity(n_complexity)\n",
    "basis = traj.get_basis(times=times)\n",
    "\n",
    "# generate noiseless data.\n",
    "traj.set_coeffs(1)\n",
    "__, D_gt = get_measurements(traj, anchors[:2, :], times=times)\n",
    "mask = create_mask(*D_gt.shape, strategy='single_time') \n",
    "D_gt *= mask\n",
    "\n",
    "C_gt_vec = traj.coeffs.reshape((-1,))\n",
    "cost_gt = cost_function(C_gt_vec, D_gt, anchors[:2, :], basis)\n",
    "assert np.sum(np.abs(cost_gt)) < 1e-5, np.sum(np.abs(cost_gt))\n",
    "\n",
    "# noisy data\n",
    "D_noisy = add_noise(D_gt, noise_sigma=0.1)\n",
    "D_noisy *= mask\n",
    "\n",
    "\n",
    "#### Choose which one to test.\n",
    "D_here = D.copy()\n",
    "#D_here = D_gt\n",
    "#D_here = D_noisy\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "Chat = alternativePseudoInverse(D_here, anchors[:2, :], basis, weighted=False)\n",
    "traj.set_coeffs(coeffs=Chat)\n",
    "traj.plot_pretty(times=times, ax=ax, label='ours')\n",
    "\n",
    "x0 = Chat.copy().reshape((-1,))\n",
    "Cref = least_squares_lm(D_here, anchors, basis, x0)\n",
    "\n",
    "traj.set_coeffs(coeffs=Cref)\n",
    "traj.plot_pretty(times=times, ax=ax, label='LM, init ours', ls=':')\n",
    "\n",
    "x0 = np.random.rand(*Chat.shape).reshape((-1, )) * 10\n",
    "Crand = least_squares_lm(D_here, anchors, basis, x0)\n",
    "traj.set_coeffs(coeffs=Crand)\n",
    "traj.plot_pretty(times=times, ax=ax, label='LM, init random')\n",
    "\n",
    "ax.legend()\n",
    "\n",
    "print('OURS error', calculate_error(Chat, traj.coeffs))\n",
    "print('LM refined error', calculate_error(Cref, traj.coeffs))\n",
    "print('LM random error', calculate_error(Crand, traj.coeffs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def init_lm(coeffs_real, method='ellipse', **kwargs):\n",
    "    if 'ellipse' in method:\n",
    "        coeffs = np.zeros(coeffs_real.shape)\n",
    "        center = coeffs_real[:, 0]\n",
    "        rx = np.max(coeffs_real[0, 1:]) - np.min(coeffs_real[0, 1:])\n",
    "        ry = np.max(coeffs_real[1, 1:]) - np.min(coeffs_real[1, 1:])\n",
    "        coeffs[0, 0] = center[0]\n",
    "        coeffs[1, 0] = center[1]\n",
    "        coeffs[0, 1] = rx\n",
    "        coeffs[1, 2] = ry\n",
    "        return coeffs\n",
    "    elif 'noise' in method:\n",
    "        sigma = kwargs.get('sigma', 0.1)\n",
    "        return coeffs_real + np.random.normal(scale=sigma)\n",
    "    elif 'real' in method:\n",
    "        return coeffs_real\n",
    "    else:\n",
    "        raise NotImplementedError(method)\n",
    "        \n",
    "def fit_trajectory_to_points(px, py, times, traj):\n",
    "    from fit_curve import solve_for_C\n",
    "    F = traj.get_basis(times=times)\n",
    "    R = np.c_[px.flatten(), py.flatten()].T\n",
    "    assert R.shape[0] == traj.dim\n",
    "    assert F.shape[0] == traj.n_complexity \n",
    "    assert F.shape[1] == R.shape[1]\n",
    "    return solve_for_C(R, F)\n",
    "\n",
    "traj_gt = get_trajectory(filename)\n",
    "traj_gt.set_n_complexity(n_complexity)\n",
    "coeffs_gt = fit_trajectory_to_points(full_df.px.values, full_df.py.values, \n",
    "                                     full_df.timestamp.values, traj_gt)\n",
    "        \n",
    "n_measurements_list = [20, 30, 50, 200][::-1]\n",
    "methods = ['weighted', 'srls', 'lm-real', 'lm-noise', 'lm-ellipse']\n",
    "\n",
    "for n_measurements in n_measurements_list:\n",
    "    coeffs = np.empty([traj.dim, n_complexity, 0])\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    np.random.seed(1)\n",
    "    indices = np.random.choice(D.shape[0], n_measurements, replace=False)\n",
    "\n",
    "    D_small = D[indices, :]\n",
    "    times_small = np.array(times)[indices]\n",
    "\n",
    "    for k, method in enumerate(methods): \n",
    "        if method == 'weighted':\n",
    "            basis = traj.get_basis(times=times_small)\n",
    "\n",
    "            t1 = time.time()\n",
    "            Chat = alternativePseudoInverse(D_small, anchors[:2, :], basis, weighted=True)\n",
    "            t2 = time.time()\n",
    "\n",
    "            traj.set_coeffs(coeffs=Chat)\n",
    "            traj.plot_pretty(times=times, color=f'C{k}', ax=ax, label=method)\n",
    "        elif method == 'srls':\n",
    "            t1 = time.time()\n",
    "            points = pointwise_srls(D, anchors, basis, traj, indices)\n",
    "            t2 = time.time()\n",
    "\n",
    "            label = 'SRLS'\n",
    "            for x in points:\n",
    "                ax.scatter(*x, color=f'C{k}', label=label)\n",
    "                label=None\n",
    "        elif 'lm' in method:\n",
    "            basis = traj.get_basis(times=times_small)\n",
    "\n",
    "            coeffs_init = init_lm(coeffs_gt, method=method, sigma=1.0)\n",
    "            traj.set_coeffs(coeffs=coeffs_init)\n",
    "            traj.plot_pretty(times=times, color=f'C{k}', ax=ax, label=method+' init', linestyle=':')\n",
    "\n",
    "            x0 = coeffs_init.reshape((-1,))\n",
    "            t1 = time.time()\n",
    "            Crand = least_squares_lm(D_small, anchors, basis, x0)\n",
    "            t2 = time.time()\n",
    "\n",
    "            traj.set_coeffs(coeffs=Crand)\n",
    "            traj.plot_pretty(times=times, color=f'C{k}', ax=ax, label=method)\n",
    "        print(f'{method} took {t2-t1:.2f} seconds.')\n",
    "        \n",
    "traj_gt.set_coeffs(coeffs=coeffs_gt)\n",
    "traj_gt.plot_pretty(times=times, color='black', ax=ax, label='ground truth fitted', linestyle=':')\n",
    "\n",
    "ax.plot(full_df.px, full_df.py, color='black', label='ground truth')\n",
    "ax.set_xlabel('x [m]')\n",
    "ax.set_title('N={}'.format(n_measurements))\n",
    "\n",
    "ax.set_xlim(*xlim)\n",
    "ax.set_ylim(*ylim)\n",
    "\n",
    "axs[0].set_ylabel('y [m]')\n",
    "legend = ax.legend(loc='lower right', ncol=3, facecolor='white', framealpha=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_measurements = 200\n",
    "sigmas = [0.1, 1, 2, 5, 10]\n",
    "fig, axs = plt.subplots(1, len(sigmas), sharex=True, sharey=True)\n",
    "fig.set_size_inches(3*len(sigmas), 5)\n",
    "\n",
    "np.random.seed(1)\n",
    "method = 'noise'\n",
    "k = 1\n",
    "for ax, sigma in zip(axs, sigmas):\n",
    "    print(f'sigma {sigma}')\n",
    "    coeffs = np.empty([traj.dim, n_complexity, 0])\n",
    "    indices = np.random.choice(D.shape[0], n_measurements, replace=False)\n",
    "\n",
    "    D_small = D[indices, :]\n",
    "    times_small = np.array(times)[indices]\n",
    "    basis = traj.get_basis(times=times_small)\n",
    "    \n",
    "    coeffs_init = init_lm(coeffs_gt, method=method, sigma=sigma)\n",
    "    \n",
    "    x0 = coeffs_init.reshape((-1,))\n",
    "    Crand = least_squares_lm(D_small, anchors, basis, x0)\n",
    "    \n",
    "    # plotting\n",
    "    ax.set_title(f'sigma={sigma}')\n",
    "    traj.set_coeffs(coeffs=coeffs_init)\n",
    "    traj.plot_pretty(times=times, color=f'C{k}', ax=ax, label=method+' init', linestyle=':')\n",
    "    traj.set_coeffs(coeffs=Crand)\n",
    "    traj.plot_pretty(times=times, color=f'C{k}', ax=ax, label=method+' res')\n",
    "    \n",
    "    traj.set_coeffs(coeffs=coeffs_gt)\n",
    "    traj.plot_pretty(times=times, color='black', ax=ax, label='ground truth fitted', linestyle=':')\n",
    "    #ax.plot(full_df.px, full_df.py, color='black', label='ground truth')\n",
    "\n",
    "ax.set_xlabel('x [m]')\n",
    "\n",
    "ax.set_xlim(*xlim)\n",
    "ax.set_ylim(*ylim)\n",
    "\n",
    "axs[0].set_ylabel('y [m]')\n",
    "legend = ax.legend(loc='lower right', ncol=3, facecolor='white', framealpha=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterative algorithms\n",
    "\n",
    "In this section, we apply our trajectory estimation iteratively: either using a constant time window (Averaging algortihm) or building up and refining the trajectory as we go (Build up algorithm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "period_it = 10\n",
    "if dataname == 'uah1':\n",
    "    # for iterative.\n",
    "    n_complexity_it = 2\n",
    "    model_it = 'polynomial'\n",
    "    t_window_it = 80\n",
    "elif dataname == 'Plaza1':\n",
    "    # for iterative.\n",
    "    n_complexity_it = 3\n",
    "    model_it = 'full_bandlimited'\n",
    "    period_it = 40\n",
    "    t_window_it = 20\n",
    "elif dataname == 'Plaza2':\n",
    "    # for iterative.\n",
    "    n_complexity_it = 3\n",
    "    model_it = 'bandlimited'\n",
    "    period_it = 40\n",
    "    t_window_it = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj_it = traj.copy()\n",
    "traj_it.set_n_complexity(n_complexity_it)\n",
    "traj_it.model = model_it\n",
    "traj_it.period = period_it\n",
    "basis = traj_it.get_basis(times=times)\n",
    "print('Using trajectory model: \\n model={}, K={}, period={}'.format(traj_it.model, traj_it.n_complexity, traj_it.period))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Averaging algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from iterative_algorithms import averaging_algorithm\n",
    "print('averaging with time window', t_window_it)\n",
    "C_list, t_list = averaging_algorithm(D, anchors[:2, :], basis, times, t_window=t_window_it)\n",
    "ax1 = plot_individual(C_list, t_list, traj_it)\n",
    "ax1.plot(ground_truth_pos.px, ground_truth_pos.py, color='black')\n",
    "result_df = get_smooth_points(C_list, t_list, traj_it)\n",
    "ax2 = plot_smooth(result_df)\n",
    "ax2.plot(ground_truth_pos.px, ground_truth_pos.py, color='black')\n",
    "[[ax.set_xlim(*xlim), ax.set_ylim(*ylim)] for ax in [ax1, ax2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Build up algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from iterative_algorithms import build_up_algorithm\n",
    "\n",
    "C_list, t_list = build_up_algorithm(D, anchors[:2, :], basis, times, eps=eps, verbose=False)\n",
    "ax1 = plot_individual(C_list, t_list, traj_it.copy())\n",
    "ax1.plot(ground_truth_pos.px, ground_truth_pos.py, color='black')\n",
    "\n",
    "result_df = get_smooth_points(C_list, t_list, traj_it)\n",
    "ax2 = plot_smooth(result_df)\n",
    "ax2.plot(ground_truth_pos.px, ground_truth_pos.py, color='black')\n",
    "[[ax.set_xlim(*xlim), ax.set_ylim(*ylim)] for ax in [ax1, ax2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
