{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Public dataset evaluation\n",
    "\n",
    "In this notebook we test and evaluabte publicly available datasets (see *datasets/* folder)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib notebook\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from public_data_utils import *\n",
    "\n",
    "plt.rcParams['figure.figsize'] = 7, 3\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "matplotlib.rcParams['ps.fonttype'] = 42\n",
    "\n",
    "# set the random seed so can reproduce when something didn't work. \n",
    "# (only when cells are run in order)\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains functionality to evaluate the proposed algorithms on real datasets. To simply reproduce the plots from the paper you can directly run GenerateAllFigures. \n",
    "\n",
    "# Preparation\n",
    "\n",
    "### 1. Download .mat files and save them in folder ./datasets/ (can simply run download_datasets.sh)\n",
    "\n",
    "WiFi: http://www.robesafe.es/repository/UAHWiFiDataset/\n",
    "\n",
    "Lawnmower: https://panda.frc.ri.cmu.edu/projects/emergencyresponse/RangeData/download.html\n",
    "\n",
    "See datasets/README.md for file description.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Choose dataset and range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filename = 'datasets/uah1.mat' # fingers\n",
    "filename = 'datasets/Plaza1.mat'; # zig zag. \n",
    "#filename = 'datasets/Plaza2.mat' # triangle\n",
    "#filename = 'datasets/Gesling1.mat' # not working\n",
    "#filename = 'datasets/Gesling2.mat' # not working\n",
    "#filename = 'datasets/Gesling3.mat' # \n",
    "\n",
    "full_df, anchors_df, traj = read_dataset(filename)\n",
    "xlim, ylim = get_plotting_params(filename)\n",
    "print(xlim, ylim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "#%matplotlib inline\n",
    "fig, axs = plt.subplots(1, 2)\n",
    "plot_df = full_df\n",
    "sns.scatterplot(data=plot_df, x='px', y='py', hue='timestamp', linewidth=0.0, ax=axs[0])\n",
    "sns.scatterplot(data=plot_df, x='timestamp', y='py', hue='timestamp', linewidth=0.0, ax=axs[1])\n",
    "sns.scatterplot(data=anchors_df, x='px', y='py', linewidth=0.0,  ax=axs[0], color='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. (optional) plot distance measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2)\n",
    "range_df = full_df.loc[full_df.system_id == range_system_id].copy()\n",
    "sns.scatterplot(data=range_df, x='px', y='py', hue='timestamp', linewidth=0.0, ax=axs[0])\n",
    "sns.scatterplot(data=anchors_df, x='px', y='py', linewidth=0.0,  ax=axs[0], color='red')\n",
    "for a_id, px, py in zip(anchors_df.anchor_id, anchors_df.px, anchors_df.py):\n",
    "    print(a_id, px, py)\n",
    "    axs[0].annotate(s='a{}'.format(a_id), xy=(px+2,py+2), color='red')\n",
    "axs[0].legend('')\n",
    "sns.scatterplot(data=range_df, x='timestamp', y='px', hue='timestamp', linewidth=0.0, ax=axs[1])\n",
    "\n",
    "plot_distance_times(full_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(5, 2)\n",
    "ax = plot_distance_errors(full_df, ax=ax)\n",
    "#savefig(fig, 'results/accuracy.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_names = sorted(range_df.anchor_name.unique())\n",
    "print(anchor_names)\n",
    "fig, axs = plt.subplots(1, len(anchor_names), sharey=True)\n",
    "fig.set_size_inches(15, 4)\n",
    "for ax, anchor_name in zip(axs, anchor_names):\n",
    "    plot_df = range_df.loc[range_df.anchor_name==anchor_name].copy()\n",
    "    plot_df.loc[:, 'distance error'] = plot_df.distance.values - plot_df.distance_gt.values\n",
    "    plot_df.loc[:, 'anchor name'] = plot_df.anchor_name.values\n",
    "    anchors_df.loc[:, 'anchor name'] = anchors_df.anchor_name.values\n",
    "    sns.scatterplot(data=plot_df, x='px', y='py', hue='anchor name', size='distance error',\n",
    "                    hue_order=anchor_names, linewidth=0.0, alpha=0.8, ax=ax, legend=False)\n",
    "    anchors_df = anchors_df.apply(pd.to_numeric, downcast='float', errors='ignore', axis=0)\n",
    "    sns.scatterplot(data=anchors_df, x='px', y='py', hue='anchor name',\n",
    "                    linewidth=0.0, legend=False, ax=ax)\n",
    "    ax.axis('equal')\n",
    "    ax.set_title(anchor_name)\n",
    "g = sns.scatterplot(data=anchors_df, x='px', y='py', hue='anchor name',\n",
    "                    linewidth=0.0, legend='full', ax=ax)\n",
    "g.legend(loc='center left', bbox_to_anchor=(1.25, 0.5), ncol=1)\n",
    "fig.suptitle('Scatter plots with size proportional to distance error.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot and print results from generate_results.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert all numerical columns to float, ignore non-numeric.\n",
    "fname = 'results/algorithms_sunday.pkl'\n",
    "result_df = pd.read_pickle(fname)\n",
    "result_df = result_df.apply(pd.to_numeric, errors='ignore')\n",
    "#print_table = result_df[result_df.n_measurements.isin([40, 100, 200, 300, 499])]\n",
    "print_table = result_df[(result_df.n_complexity >= 5) & (result_df.n_measurements >= 100)]\n",
    "pt = pd.pivot_table(print_table, values='mse', index='method', columns=['n_measurements', 'n_complexity'], \n",
    "               aggfunc=['mean', 'std']).reindex(['gt','srls raw', 'srls', 'rls raw', 'rls', 'lm-ellipse', 'lm-ours-weighted',\n",
    "                                                 'ours', 'ours-weighted'])\n",
    "\n",
    "def highlight_min(data, exclude=[0], color='red', index=0):\n",
    "    \"\"\"\n",
    "    :param exclude: rows indices to exclude for calculating min.\n",
    "    :param index: set to 0 for smallest, 1 for second smallest, etc.\n",
    "    \"\"\"\n",
    "    attr = 'background-color: {}'.format(color)\n",
    "    \n",
    "    if data.ndim == 1:  # Series from .apply(axis=0) or axis=1\n",
    "        indices = [i for i in range(len(data)) if i not in exclude]\n",
    "        is_min = data == sorted(data[indices])[index]\n",
    "        if sum(is_min) > 1:\n",
    "            return ['']*len(data)\n",
    "        return [attr if v else '' for v in is_min]\n",
    "    \n",
    "def highlight_both(data, exclude=[0]):\n",
    "    attr1 = highlight_min(data, exclude=exclude, color='red', index=0)\n",
    "    attr2 = highlight_min(data, exclude=exclude, color='orange', index=1)\n",
    "    return [a1+a2 for a1, a2 in zip(attr1, attr2)]\n",
    "    \n",
    "styler = pt.style.apply(highlight_min, axis=0)\n",
    "pt = pt.style.apply(highlight_both, axis=0)\n",
    "pd.set_option('precision', 2)\n",
    "pd.set_option('max_columns', 100)\n",
    "pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = result_df[result_df.mae < 100]\n",
    "plot_df = plot_df[plot_df.n_measurements > 100]\n",
    "fg = sns.FacetGrid(data=plot_df, col='n_complexity', hue='method', legend_out=True)\n",
    "fg.map(plt.semilogy, 'n_measurements', 'mae', linestyle='', marker='.', alpha=0.5)\n",
    "legend = plt.gca().get_legend()\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# understand why N=100, K=19 is so bad...\n",
    "df = result_df.loc[(result_df.n_measurements==100) & (result_df.n_complexity==19), :]\n",
    "fig, ax = plt.subplots()\n",
    "for method, df_m in df.groupby('method'):\n",
    "    ax.scatter(df_m.n_it, df_m.mse, label=method)\n",
    "ax.set_yscale('log')\n",
    "ax.legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sandbox\n",
    "\n",
    "Space to try out stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate_dataset import compute_distance_matrix, compute_anchors\n",
    "chosen_distance = 'distance'\n",
    "#chosen_distance = 'distance_gt'\n",
    "anchor_names = None\n",
    "\n",
    "## Construct anchors. \n",
    "anchors = compute_anchors(anchors_df, anchor_names)\n",
    "print(anchors.shape)\n",
    "\n",
    "## Construct times.\n",
    "times = full_df[full_df.system_id == range_system_id].timestamp.unique()\n",
    "\n",
    "## Construct D.\n",
    "D, times = compute_distance_matrix(full_df, anchors_df, anchor_names, times, chosen_distance)\n",
    "print(D.shape)\n",
    "if np.sum(D > 0) > D.shape[0]:\n",
    "    print('Warning: multiple measurements for times:{}/{}!'.format(\n",
    "          np.sum(np.sum(D > 0, axis=1)>1), D.shape[0]))\n",
    "\n",
    "## Construct ground truth.\n",
    "points_gt = get_ground_truth(full_df, times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from other_algorithms import apply_algorithm\n",
    "from fit_curve import fit_trajectory\n",
    "print(D.shape)\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(points_gt.px, points_gt.py, s=10)\n",
    "\n",
    "traj.set_n_complexity(2)\n",
    "\n",
    "coeffs, __, __ = apply_algorithm(traj, D, times, anchors, method='ours-weighted')\n",
    "traj.set_coeffs(coeffs=coeffs)\n",
    "traj.plot_pretty(times=times, ax=ax, color='red', label='fitted')\n",
    "\n",
    "traj.print()\n",
    "coeffs = fit_trajectory(points_gt.T, times, traj)\n",
    "traj.set_coeffs(coeffs=coeffs)\n",
    "traj.plot_pretty(times=times, ax=ax, color='green', label='best fit')\n",
    "ax.set_xlim(*xlim)\n",
    "ax.set_ylim(*ylim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
