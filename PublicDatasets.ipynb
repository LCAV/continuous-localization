{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib notebook\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from public_data_utils import *\n",
    "\n",
    "plt.rcParams['figure.figsize'] = 7, 3\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "matplotlib.rcParams['ps.fonttype'] = 42\n",
    "\n",
    "# set the random seed so can reproduce when something didn't work. \n",
    "# (only when cells are run in order)\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Public dataset evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains functionality to evaluate the proposed algorithms on real datasets. To simply reproduce the plots from the paper you can directly run GenerateAllFigures. \n",
    "\n",
    "# Preparation\n",
    "\n",
    "### 1. Download .mat files and save them in folder ./datasets/ (can simply run download_datasets.sh)\n",
    "\n",
    "WiFi: http://www.robesafe.es/repository/UAHWiFiDataset/\n",
    "\n",
    "Lawnmower: https://panda.frc.ri.cmu.edu/projects/emergencyresponse/RangeData/download.html\n",
    "\n",
    "See datasets/README.md for file description.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Choose dataset and range\n",
    "\n",
    "Note that currently fully functional are only Plaza1 and Plaza2. The others are still kept here for development purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filename = 'datasets/uah1.mat' # fingers\n",
    "filename = 'datasets/Plaza1.mat'; # zig zag. \n",
    "#filename = 'datasets/Plaza2.mat' # \n",
    "#filename = 'datasets/Gesling1.mat' # not working\n",
    "#filename = 'datasets/Gesling2.mat' # not working\n",
    "#filename = 'datasets/Gesling3.mat' # \n",
    "\n",
    "original_df, anchors_df, traj = read_dataset(filename, verbose=True)\n",
    "xlim, ylim = get_plotting_params(filename)\n",
    "print(xlim, ylim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from generate_results import calibrate\n",
    "\n",
    "calibrate(original_df)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "for anchor_id in original_df.anchor_id.unique():\n",
    "    if anchor_id == 'GT':\n",
    "        continue\n",
    "    gt_df = original_df[original_df.anchor_id==anchor_id]\n",
    "    fig, axs = plt.subplots(1, 2)\n",
    "    fig.set_size_inches(5, 3)\n",
    "    axs[0].scatter(gt_df.px, gt_df.py, s=1.0)\n",
    "    \n",
    "    axs[1].scatter(gt_df.distance_gt, gt_df.distance, s=1.0, label='raw')\n",
    "    axs[1].scatter(gt_df.distance_gt, gt_df.distance_calib, s=1.0, label='calibrated')\n",
    "    axs[1].scatter(gt_df.distance_gt, gt_df.distance_gt, s=1.0, label='ideal')\n",
    "    fig.suptitle(f\"anchor id {anchor_id}\")\n",
    "    ax.plot(gt_df.timestamp, gt_df.distance, label=anchor_id)\n",
    "    axs[1].legend()    \n",
    "    \n",
    "    axs[0].set_xlabel('x [m]')\n",
    "    axs[0].set_ylabel('y [m]')\n",
    "    axs[1].set_xlabel('real d [m]')\n",
    "    axs[1].set_ylabel('measured d [m]')\n",
    "    \n",
    "ax.set_xlabel('timestamp')\n",
    "ax.set_ylabel('distance')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "#%matplotlib notebook\n",
    "from generate_results_polynomial import TIME_RANGES\n",
    "from math import ceil, floor\n",
    "\n",
    "if 'Plaza1' in filename:\n",
    "    plot_df = original_df[(original_df.timestamp > 300) & (original_df.timestamp < 1400)]\n",
    "    time_ranges = TIME_RANGES\n",
    "    print(original_df.timestamp.min(), original_df.timestamp.max())\n",
    "    print(time_ranges)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    sns.scatterplot(data=plot_df, x='timestamp', y='px', color='red', linewidth=0.0, ax=ax, s=1.0)\n",
    "    sns.scatterplot(data=plot_df, x='timestamp', y='py', color='green', linewidth=0.0, ax=ax, s=1.0)\n",
    "\n",
    "    side = np.sqrt(len((time_ranges)))\n",
    "    fig, axs2 = plt.subplots(ceil(side), floor(side), sharex=False, sharey=True)\n",
    "    fig.suptitle('piecewise linear coordinates over time', y=0.95)\n",
    "    fig.set_size_inches(1.0*np.array(axs2.shape))\n",
    "    axs2 = axs2.reshape((-1,))\n",
    "    for ax2, time_range in zip(axs2, time_ranges):\n",
    "        plot_df = original_df[(original_df.timestamp > time_range[0]) & (original_df.timestamp < time_range[1])]\n",
    "        ax2.scatter(plot_df.timestamp, plot_df.px, color='red', s=1.0, label='x')\n",
    "        ax2.scatter(plot_df.timestamp, plot_df.py, color='green', s=1.0, label='y')\n",
    "\n",
    "        ax.scatter(plot_df.timestamp, plot_df.px, color='black', s=1.0)\n",
    "        ax.scatter(plot_df.timestamp, plot_df.py, color='black', s=1.0)\n",
    "\n",
    "    ax2.legend(loc='lower left', bbox_to_anchor=[1.0, 0.0])\n",
    "    mask = np.array([False] * len(original_df))\n",
    "    for time_range in time_ranges:\n",
    "        mask = mask | ((original_df.timestamp > time_range[0]) & (original_df.timestamp < time_range[1])).values\n",
    "    full_df = original_df[mask]\n",
    "else:\n",
    "    full_df = original_df\n",
    "    print('using all measurements for', filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. (optional) plot distance measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plot_distance_times(full_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. (optional) plot distance distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(5, 1, sharex=False)\n",
    "fig.set_size_inches(5, 10)\n",
    "ax = plot_distance_errors(full_df, ax=axs[0])\n",
    "#savefig(fig, 'results/accuracy.pdf')\n",
    "\n",
    "axs[1].set_ylabel('(d - d_gt)')\n",
    "distance_error = full_df.distance - full_df.distance_gt\n",
    "axs[1].hist(distance_error, bins=30)\n",
    "\n",
    "axs[2].set_ylabel('1/d(d**2 - d_gt**2)')\n",
    "distance_error = (full_df.distance.values.astype(np.float32)**2 - full_df.distance_gt.values.astype(np.float32)**2)/(full_df.distance_gt.values.astype(np.float32) + 1e-3)\n",
    "axs[2].hist(distance_error, bins=30)\n",
    "\n",
    "axs[3].set_ylabel('(d**2 - d_gt**2)')\n",
    "distance_error = full_df.distance.values.astype(np.float32)**2 - full_df.distance_gt.values.astype(np.float32)**2\n",
    "axs[3].hist(distance_error, bins=30)\n",
    "\n",
    "axs[4].set_ylabel('(d - d_gt)**2')\n",
    "distance_error = (full_df.distance.values.astype(np.float32) - full_df.distance_gt.values.astype(np.float32))**2\n",
    "_ = axs[4].hist(distance_error, bins=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. (optional) plot distance error spacially "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "range_df = full_df.loc[full_df.system_id=='Range']\n",
    "\n",
    "anchor_names = sorted(range_df.anchor_name.unique())\n",
    "print(anchor_names)\n",
    "fig, axs = plt.subplots(1, len(anchor_names), sharey=True)\n",
    "fig.set_size_inches(15, 4)\n",
    "for ax, anchor_name in zip(axs, anchor_names):\n",
    "    plot_df = range_df.loc[range_df.anchor_name==anchor_name].copy()\n",
    "    plot_df.loc[:, 'distance error'] = plot_df.distance.values - plot_df.distance_gt.values\n",
    "    plot_df.loc[:, 'anchor name'] = plot_df.anchor_name.values\n",
    "    anchors_df.loc[:, 'anchor name'] = anchors_df.anchor_name.values\n",
    "    sns.scatterplot(data=plot_df, x='px', y='py', hue='anchor name', size='distance error',\n",
    "                    hue_order=anchor_names, linewidth=0.0, alpha=0.8, ax=ax, legend=False)\n",
    "    anchors_df = anchors_df.apply(pd.to_numeric, downcast='float', errors='ignore', axis=0)\n",
    "    sns.scatterplot(data=anchors_df, x='px', y='py', hue='anchor name',\n",
    "                    linewidth=0.0, legend=False, ax=ax)\n",
    "    ax.set_title(anchor_name)\n",
    "g = sns.scatterplot(data=anchors_df, x='px', y='py', hue='anchor name',\n",
    "                    linewidth=0.0, legend='full', ax=ax)\n",
    "g.legend(loc='center left', bbox_to_anchor=(1.25, 0.5), ncol=1)\n",
    "fig.suptitle('Scatter plots with size proportional to distance error.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reconstruction Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## bandlimited table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from table_tools import *\n",
    "def format_here(number):\n",
    "    if number > 10000:\n",
    "        return '{:.2e}'.format(number)\n",
    "    else:\n",
    "        return '{:.1f}'.format(number)\n",
    "\n",
    "fname = 'results/bandlimited_tuesday.pkl'\n",
    "outname = 'results/table_bandlimited.tex'\n",
    "\n",
    "#fname = 'results/bandlimited_tuesday_calib.pkl'\n",
    "#outname = 'results/table_bandlimited_calib.tex'\n",
    "\n",
    "result_df = pd.read_pickle(fname)\n",
    "# convert all numerical columns to float, ignore non-numeric.\n",
    "result_df = result_df.apply(pd.to_numeric, errors='ignore')\n",
    "#print_table = result_df[result_df.n_measurements.isin([40, 100, 200, 300, 499])]\n",
    "print_table = result_df[(result_df.n_complexity >= 5) & (result_df.n_measurements >= 100)]\n",
    "print_table = print_table[print_table.n_measurements.isin([100, 300, 499])]\n",
    "methods = ['gt','srls raw', 'srls', 'rls raw', 'rls', 'lm-ellipse', \n",
    "           'lm-ours-weighted', 'ours', 'ours-weighted']\n",
    "#pretty_print_table(print_table, methods=methods, value='cost_rls')\n",
    "styler, __ = pretty_print_table(print_table, methods=methods, value='mse')\n",
    "styler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = ['gt','srls raw', 'srls', 'rls raw', 'rls', 'lm-ellipse', \n",
    "           'lm-ours-weighted', 'ours', 'ours-weighted']\n",
    "__, pt = pretty_print_table(print_table, methods=methods, value='mse')\n",
    "latex_print(pt, methods, outname, float_format=format_here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some bandlimited sanity checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot error vs n measurements and n complexity\n",
    "plot_df = result_df[result_df.mae < 100]\n",
    "plot_df = plot_df[plot_df.n_measurements > 100]\n",
    "fg = sns.FacetGrid(data=plot_df, col='n_complexity', hue='method', legend_out=True)\n",
    "fg.map(plt.semilogy, 'n_measurements', 'mae', linestyle='', marker='.', alpha=0.5)\n",
    "legend = plt.gca().get_legend()\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# understand why N=100, K=19 is so bad...\n",
    "df = result_df.loc[(result_df.n_measurements==100) & (result_df.n_complexity==19), :]\n",
    "fig, ax = plt.subplots()\n",
    "for method, df_m in df.groupby('method'):\n",
    "    ax.scatter(df_m.n_it, df_m.mse, label=method)\n",
    "ax.set_yscale('log')\n",
    "ax.legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## polynomial table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = 'results/polynomial_tuesday.pkl'\n",
    "outname = 'results/table_polynomial.tex'\n",
    "\n",
    "#fname = 'results/polynomial_tuesday_calib.pkl'\n",
    "#outname = 'results/table_polynomial_calib.tex'\n",
    "\n",
    "result_df = pd.read_pickle(fname)\n",
    "# convert all numerical columns to float, ignore non-numeric.\n",
    "result_df = result_df.apply(pd.to_numeric, errors='ignore')\n",
    "print_table = result_df\n",
    "print_table = print_table[print_table.n_measurements.isin([10, 20, 30, 50])]\n",
    "\n",
    "methods = ['gt','srls raw', 'srls', 'rls raw', 'rls', 'lm-line', \n",
    "           'lm-ours-weighted', 'ours', 'ours-weighted']\n",
    "styler, __ = pretty_print_table(print_table, methods=methods, value='mse')\n",
    "styler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "__, pt = pretty_print_table(print_table, methods=methods, value='mse')\n",
    "latex_print(pt, methods, outname, index_names=False, index=False, float_format=format_here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sandbox (space to try out stuff)\n",
    "\n",
    "### Example reconstructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate_dataset import compute_distance_matrix, compute_anchors\n",
    "chosen_distance = 'distance'\n",
    "#chosen_distance = 'distance_gt'\n",
    "anchor_names = None\n",
    "\n",
    "## Construct anchors. \n",
    "anchors = compute_anchors(anchors_df, anchor_names)\n",
    "print(anchors.shape)\n",
    "\n",
    "## Construct times.\n",
    "times = full_df[full_df.system_id == range_system_id].timestamp.unique()\n",
    "\n",
    "## Construct D.\n",
    "D, times = compute_distance_matrix(full_df, anchors_df, anchor_names, times, chosen_distance)\n",
    "print(D.shape)\n",
    "if np.sum(D > 0) > D.shape[0]:\n",
    "    print('Warning: multiple measurements for times:{}/{}!'.format(\n",
    "          np.sum(np.sum(D > 0, axis=1)>1), D.shape[0]))\n",
    "\n",
    "## Construct ground truth.\n",
    "points_gt = get_ground_truth(full_df, times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from other_algorithms import apply_algorithm\n",
    "from fit_curve import fit_trajectory\n",
    "print(D.shape)\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(points_gt.px, points_gt.py, s=10)\n",
    "\n",
    "traj.set_n_complexity(3)\n",
    "\n",
    "#method = 'ours-weighted'\n",
    "method = 'lm-line'\n",
    "coeffs, __, __ = apply_algorithm(traj, D, times, anchors, method=method)\n",
    "traj.set_coeffs(coeffs=coeffs)\n",
    "traj.plot_pretty(times=times, ax=ax, color='red', label='fitted')\n",
    "\n",
    "traj.print()\n",
    "coeffs = fit_trajectory(points_gt.T, times, traj)\n",
    "traj.set_coeffs(coeffs=coeffs)\n",
    "traj.plot_pretty(times=times, ax=ax, color='green', label='best fit')\n",
    "ax.set_xlim(*xlim)\n",
    "ax.set_ylim(*ylim)\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Piecewise linear reconstructions: correlation between cost and reconstruction error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "result_df = pd.read_pickle('results/polynomial_tuesday_calib.pkl')\n",
    "result_df = pd.read_pickle('results/polynomial_tuesday.pkl')\n",
    "\n",
    "chosen_measure = 'mse'\n",
    "\n",
    "for N, df_N in result_df.groupby('n_measurements'):\n",
    "    Ks = df_N.n_complexity.unique()\n",
    "    fig, axs = plt.subplots(2, len(Ks), squeeze=False, sharey=True)\n",
    "    fig.suptitle(f'N={N}')\n",
    "    i = 0\n",
    "    for K, df_K in df_N.groupby('n_complexity'):\n",
    "        ax1, ax2 = axs[:, i]\n",
    "        for method, df_method in df_K.groupby('method'):\n",
    "            ax1.plot(df_method[chosen_measure].values, label=method)\n",
    "            ax2.scatter(df_method['cost_rls'].values, df_method[chosen_measure], label=method)\n",
    "        ax2.set_xscale('log')\n",
    "        ax2.set_yscale('log')\n",
    "        ylim_chosen = min(200, df_method[chosen_measure].max()) \n",
    "        xlim_rls = min(2000, df_method['cost_rls'].max())\n",
    "        ax1.set_ylim([1, ylim_chosen])\n",
    "        ax2.set_ylabel(str.upper(chosen_measure))\n",
    "        ax2.set_xlim([1, xlim_rls])\n",
    "        ax2.legend(loc='lower left', bbox_to_anchor=[1, 0])\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
