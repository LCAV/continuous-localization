{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Public dataset evaluation\n",
    "\n",
    "In this notebook we test and evaluabte publicly available datasets (see *datasets/* folder)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.io import loadmat\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from data_utils import *\n",
    "\n",
    "plt.rcParams['figure.figsize'] = 7, 3\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "matplotlib.rcParams['ps.fonttype'] = 42\n",
    "\n",
    "# set the random seed so can reproduce when something didn't work. \n",
    "# (only when cells are run in order)\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains functionality to evaluate the proposed algorithms on real datasets. To simply reproduce the plots from the paper you can directly run GenerateAllFigures. \n",
    "\n",
    "# Preparation\n",
    "\n",
    "### 1. Download .mat files and save them in folder ./datasets/ (can simply run download_datasets.sh)\n",
    "\n",
    "WiFi: http://www.robesafe.es/repository/UAHWiFiDataset/\n",
    "\n",
    "Lawnmower: https://github.com/gtrll/gpslam/raw/master/matlab/data/\n",
    "\n",
    "See datasets/README.md for file description.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Choose dataset and range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trajectory_creator import get_trajectory\n",
    "\n",
    "anchor_names = None  # use all anchors by default.\n",
    "\n",
    "#filename = 'datasets/uah1.mat' # fingers\n",
    "#filename = 'datasets/Plaza1.mat'; # zig zag. \n",
    "filename = 'datasets/Plaza2.mat' # triangle\n",
    "\n",
    "verbose = False\n",
    "traj = get_trajectory(filename)\n",
    "dataname = filename.split('/')[-1].split('.')[0]\n",
    "\n",
    "if dataname == 'uah1':\n",
    "    t_window = 1.0\n",
    "    eps = 2.0\n",
    "    xlim = 0, 50\n",
    "    ylim = -20, 20\n",
    "\n",
    "    min_time = 0\n",
    "    max_time = 1000\n",
    "elif dataname == 'Plaza1':\n",
    "    t_window = 0.5\n",
    "    eps = 0.5\n",
    "    xlim = -50, 10\n",
    "    ylim = -20, 75\n",
    "\n",
    "    # choose one:\n",
    "    min_time = 0  # first big circle\n",
    "    max_time = 200  # first big circle\n",
    "    min_time = 510  # first loop\n",
    "    max_time = 600  # first loop\n",
    "    min_time = 0  # first few loops\n",
    "    max_time = 1000  # first few loops.\n",
    "elif dataname == 'Plaza2':\n",
    "    t_window = 0.1\n",
    "    eps = 0.2\n",
    "    xlim = -80, 10\n",
    "    ylim = -20, 75\n",
    "\n",
    "    min_time = 45.1\n",
    "    period = 101 - 45\n",
    "    print('period:', period)\n",
    "    num_loops = 2\n",
    "    max_time = min_time + num_loops * period\n",
    "    traj.period = period\n",
    "\n",
    "    #anchor_names = ['Range {}'.format(i) for i in range(1, 4)]\n",
    "try:\n",
    "    result_dict = loadmat(filename)\n",
    "except FileNotFoundError:\n",
    "    raise FileNotFoundError('Could not find {}. Did you run the script download_datasets?'.format(dataset))\n",
    "except Exception as e:\n",
    "    print('Unknown reading error with {}. Check if the file looks ok.'.format(filename))\n",
    "    raise e\n",
    "print('Successfully read {}'.format(filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_utils import prepare_dataset\n",
    "\n",
    "full_df, anchors_df = prepare_dataset(\n",
    "    result_dict, \n",
    "    range_system_id, \n",
    "    gt_system_id, \n",
    "    [min_time, max_time], \n",
    "    t_window)\n",
    "\n",
    "fig, axs = plt.subplots(1, 2)\n",
    "sns.scatterplot(data=full_df, x='px', y='py', hue='timestamp', linewidth=0.0, ax=axs[0])\n",
    "sns.scatterplot(data=full_df, x='timestamp', y='px', hue='timestamp', linewidth=0.0, ax=axs[1])\n",
    "sns.scatterplot(data=anchors_df, x='px', y='py', linewidth=0.0,  ax=axs[0], color='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. (optional) plot distance measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2)\n",
    "range_df = full_df.loc[full_df.system_id == range_system_id].copy()\n",
    "sns.scatterplot(data=range_df, x='px', y='py', hue='timestamp', linewidth=0.0, ax=axs[0])\n",
    "sns.scatterplot(data=anchors_df, x='px', y='py', linewidth=0.0,  ax=axs[0], color='red')\n",
    "for a_id, px, py in zip(anchors_df.anchor_id, anchors_df.px, anchors_df.py):\n",
    "    print(a_id, px, py)\n",
    "    axs[0].annotate(s='a{}'.format(a_id), xy=(px+2,py+2), color='red')\n",
    "axs[0].legend('')\n",
    "sns.scatterplot(data=range_df, x='timestamp', y='px', hue='timestamp', linewidth=0.0, ax=axs[1])\n",
    "\n",
    "plot_distance_times(full_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(5, 2)\n",
    "ax = plot_distance_errors(full_df, ax=ax)\n",
    "#savefig(fig, 'results/accuracy.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_names = sorted(range_df.anchor_name.unique())\n",
    "fig, axs = plt.subplots(1, len(anchor_names), sharey=True)\n",
    "fig.set_size_inches(15, 4)\n",
    "for ax, anchor_name in zip(axs, anchor_names):\n",
    "    plot_df = range_df.loc[range_df.anchor_name==anchor_name].copy()\n",
    "    plot_df.loc[:, 'distance error'] = plot_df.distance.values - plot_df.distance_gt.values\n",
    "    plot_df.loc[:, 'anchor name'] = plot_df.anchor_name.values\n",
    "    anchors_df.loc[:, 'anchor name'] = anchors_df.anchor_name.values\n",
    "    sns.scatterplot(data=plot_df, x='px', y='py', hue='anchor name', size='distance error', \n",
    "                    hue_order=anchor_names, linewidth=0.0, alpha=0.8, ax=ax, legend=False)\n",
    "    sns.scatterplot(data=anchors_df, x='px', y='py', hue='anchor name',\n",
    "                    hue_order=anchor_names, linewidth=0.0, legend=False, ax=ax)\n",
    "    ax.axis('equal')\n",
    "    ax.set_title(anchor_name)\n",
    "fig.suptitle('Scatter plots with size proportional to distance error.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. (optional) Filter measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = full_df[full_df.distance<=50]\n",
    "\n",
    "plot_distance_times(filtered_df)\n",
    "ax = plot_distance_errors(filtered_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reconstruction\n",
    "\n",
    "### 1. Prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate_dataset import compute_distance_matrix\n",
    "\n",
    "chosen_df = full_df\n",
    "#chosen_df = filtered_df\n",
    "chosen_distance = 'distance'\n",
    "#chosen_distance = 'distance_gt'\n",
    "\n",
    "## Construct anchors. \n",
    "if anchor_names is None:\n",
    "    anchors = anchors_df.loc[:, ['px', 'py', 'pz']].values.astype(np.float32).T\n",
    "else:\n",
    "    anchors_df = anchors_df.loc[anchors_df.anchor_name.isin(anchor_names)]\n",
    "    anchors = get_coordinates(anchors_df, anchor_names)\n",
    "\n",
    "## Construct times.\n",
    "range_df = chosen_df[chosen_df.system_id == range_system_id]\n",
    "times = range_df.timestamp.unique()\n",
    "\n",
    "## Construct D.\n",
    "D, times = compute_distance_matrix(chosen_df, anchors_df, anchor_names, times, chosen_distance)\n",
    "if np.sum(D > 0) > D.shape[0]:\n",
    "    print('Warning: multiple measurements for times:{}/{}!'.format(\n",
    "          np.sum(np.sum(D > 0, axis=1)>1), D.shape[0]))\n",
    "\n",
    "## Construct ground truth.\n",
    "ground_truth_pos = get_ground_truth(chosen_df, times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Global algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def test_hypothesis(D, dim, K):\n",
    "    import hypothesis as h\n",
    "    mask = (D)\n",
    "    p = np.sort(np.sum(mask, axis=0))[::-1]\n",
    "    assert h.limit_condition(list(p), dim+1, K)\n",
    "    \n",
    "def add_measurement(result_df, method=''):\n",
    "    global counter_df\n",
    "    result_df.loc[counter_df] = dict(\n",
    "        n_complexity=n_complexity,\n",
    "        n_measurements=n_measurements,\n",
    "        method=method,\n",
    "        n_it=n_it,\n",
    "        mae=mae,\n",
    "        mse=mse\n",
    "    )\n",
    "    counter_df += 1\n",
    "    \n",
    "from other_algorithms import pointwise_srls, apply_algorithm, error_measure\n",
    "from plotting_tools import plot_complexities, add_scalebar\n",
    "from fit_curve import fit_trajectory\n",
    "\n",
    "print('available', D.shape[0])\n",
    "list_complexities = [3, 5, 11, 19]\n",
    "list_measurements = [40, 100, 200, 300, 400, 499]\n",
    "methods = ['ours-weighted', 'ours']\n",
    "methods += ['lm-ellipse', 'lm-ours']\n",
    "methods += ['srls', 'rls']\n",
    "fname = 'results/algorithms_sunday.pkl'\n",
    "\n",
    "total_n_it = 20\n",
    "\n",
    "anchors = anchors[:2, :]\n",
    "points_gt = full_df.loc[full_df.timestamp.isin(times), ['px', 'py']].values.astype(np.float32)\n",
    "\n",
    "fig, axs = plt.subplots(len(list_measurements), len(list_complexities), sharex=True, sharey=True)\n",
    "#fig_size = [5, 1.2]\n",
    "fig_size = [5, 1.2 * len(list_measurements)]\n",
    "\n",
    "# using this complicated initialization to make sure dtypes are correct\n",
    "result_df = pd.DataFrame(columns=['n_it','n_complexity','n_measurements','mae','mse','method'])\n",
    "counter_df = 0\n",
    "\n",
    "verbose = True\n",
    "\n",
    "for j, n_complexity in enumerate(list_complexities):\n",
    "    if verbose:\n",
    "        print(f'K={n_complexity}')\n",
    "    traj.set_n_complexity(n_complexity)\n",
    "    \n",
    "    axs[0, j].set_title(f'K={n_complexity}')\n",
    "    \n",
    "    for i, n_measurements in enumerate(list_measurements):\n",
    "        axs[i, 0].set_ylabel(f'N={n_measurements}')\n",
    "        if verbose:\n",
    "            print(f'n_measurements={n_measurements}')\n",
    "        \n",
    "        for n_it in range(total_n_it):\n",
    "            indices = sorted(np.random.choice(D.shape[0], n_measurements, replace=False))\n",
    "            D_small = D[indices, :]\n",
    "            \n",
    "            # test hypothesis\n",
    "            test_hypothesis(D_small, traj.dim, traj.n_complexity)\n",
    "\n",
    "            times_small = np.array(times)[indices]\n",
    "            basis_small = traj.get_basis(times=times_small)\n",
    "            points_small = points_gt[indices, :]\n",
    "\n",
    "            results = {}\n",
    "            for method in methods: \n",
    "                C_hat, p_hat, lat_idx = apply_algorithm(traj, D_small, times_small, \n",
    "                                                   anchors, method=method)\n",
    "                results[method] = (C_hat, p_hat)\n",
    "                traj.set_coeffs(coeffs=C_hat)\n",
    "                p_fitted = traj.get_sampling_points(times=times_small).T\n",
    "                mae = error_measure(p_fitted, points_small, 'mae')\n",
    "                mse = error_measure(p_fitted, points_small, 'mse')\n",
    "                add_measurement(result_df, method=method)\n",
    "                \n",
    "                # do raw version if applicable\n",
    "                if method in ['rls', 'srls']:\n",
    "                    points_lat = points_small[lat_idx]\n",
    "                    mae = error_measure(p_hat, points_lat, 'mae')\n",
    "                    mse = error_measure(p_hat, points_lat, 'mse')\n",
    "                    add_measurement(result_df, method=method + ' raw')\n",
    "            # fit ground truth to chosen points.\n",
    "            coeffs = fit_trajectory(points_small.T, times=times_small, traj=traj)\n",
    "            traj_gt = traj.copy()\n",
    "            traj_gt.set_coeffs(coeffs=coeffs)\n",
    "            points_fitted = traj_gt.get_sampling_points(times=times_small).T\n",
    "            \n",
    "            mse = error_measure(points_fitted, points_small, 'mse')\n",
    "            mae = error_measure(points_fitted, points_small, 'mae')\n",
    "            add_measurement(result_df, 'gt')\n",
    "            \n",
    "        result_df.to_pickle(fname)\n",
    "        print('saved as', fname)\n",
    "            \n",
    "        ax = axs[i, j]\n",
    "        ax = plot_complexities(traj, times_small, results, points_fitted, ax)\n",
    "fig.set_size_inches(*fig_size) \n",
    "add_scalebar(axs[0, 0], 20, loc='lower left')\n",
    "[ax.set_xlim(*xlim) for ax in axs.flatten()]\n",
    "[ax.set_ylim(*ylim) for ax in axs.flatten()]\n",
    "result_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert all numerical columns to float, ignore non-numeric.\n",
    "fname = 'results/algorithms_sunday.pkl'\n",
    "result_df = pd.read_pickle(fname)\n",
    "result_df = result_df.apply(pd.to_numeric, errors='ignore')\n",
    "pd.set_option('precision', 2)\n",
    "print_table = result_df[result_df.n_measurements.isin([40, 300, 499])]\n",
    "pd.pivot_table(print_table, values='mae', index=['method'], columns=['n_measurements', 'n_complexity'], \n",
    "               aggfunc=['mean', 'std'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotting_backup import plot_subsample_old\n",
    "\n",
    "n_complexity = 5\n",
    "traj.set_n_complexity(n_complexity)\n",
    "\n",
    "min_number = n_complexity*(traj.dim + 2) - 1 \n",
    "print(min_number, D.shape[0])\n",
    "#n_measurements_list = np.arange(D.shape[0], min_number, step=-100)\n",
    "#n_measurements_list = [19, 20, 30, 40, 50, 100, 200, 300, 499]\n",
    "n_measurements_list = [19, 30, 60, 200][::-1]\n",
    "\n",
    "fig, axs = plot_subsample_old(traj, D, times, anchors, full_df, \n",
    "                          n_measurements_list)\n",
    "[ax.set_xlim(*xlim) for ax in axs]\n",
    "[ax.set_ylim(*ylim) for ax in axs]\n",
    "fig.set_size_inches(*fig_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare with other algorithms\n",
    "\n",
    "This part is in beta-stage. We compare against other algorithms such as Lebenberg-Marquardt optimization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from other_algorithms import init_lm \n",
    "from fit_curve import fit_trajectory\n",
    "\n",
    "traj_gt = get_trajectory(filename)\n",
    "traj_gt.set_n_complexity(n_complexity)\n",
    "R = np.c_[full_df.px.values.flatten(), full_df.py.values.flatten()].T\n",
    "coeffs_gt = fit_trajectory(R, full_df.timestamp.values, traj_gt)\n",
    "\n",
    "n_measurements_list = [20, 30, 50, 200][::-1]\n",
    "methods = ['weighted', 'srls', 'lm-real', 'lm-noise', 'lm-ellipse']\n",
    "\n",
    "for n_measurements in n_measurements_list:\n",
    "    coeffs = np.empty([traj.dim, n_complexity, 0])\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    np.random.seed(1)\n",
    "    indices = np.random.choice(D.shape[0], n_measurements, replace=False)\n",
    "\n",
    "    D_small = D[indices, :]\n",
    "    times_small = np.array(times)[indices]\n",
    "\n",
    "    for k, method in enumerate(methods): \n",
    "        if method == 'weighted':\n",
    "            basis = traj.get_basis(times=times_small)\n",
    "\n",
    "            t1 = time.time()\n",
    "            Chat = trajectory_recovery(D_small, anchors[:2, :], basis, weighted=True)\n",
    "            t2 = time.time()\n",
    "\n",
    "            traj.set_coeffs(coeffs=Chat)\n",
    "            traj.plot_pretty(times=times, color=f'C{k}', ax=ax, label=method)\n",
    "        elif method == 'srls':\n",
    "            t1 = time.time()\n",
    "            points, __ = pointwise_srls(D, anchors, traj, indices)\n",
    "            t2 = time.time()\n",
    "\n",
    "            label = 'SRLS'\n",
    "            for x in points:\n",
    "                ax.scatter(*x, color=f'C{k}', label=label)\n",
    "                label=None\n",
    "        elif 'lm' in method:\n",
    "            basis = traj.get_basis(times=times_small)\n",
    "\n",
    "            coeffs_init = init_lm(coeffs_gt, method=method, sigma=1.0)\n",
    "            traj.set_coeffs(coeffs=coeffs_init)\n",
    "            traj.plot_pretty(times=times, color=f'C{k}', ax=ax, label=method+' init', linestyle=':')\n",
    "\n",
    "            x0 = coeffs_init.reshape((-1,))\n",
    "            #print(x0)\n",
    "            t1 = time.time()\n",
    "            Crand = least_squares_lm(D_small, anchors, basis, x0, verbose=False)\n",
    "            t2 = time.time()\n",
    "\n",
    "            traj.set_coeffs(coeffs=Crand)\n",
    "            traj.plot_pretty(times=times, color=f'C{k}', ax=ax, label=method)\n",
    "        #print(f'{method} took {t2-t1:.2f} seconds.')\n",
    "        \n",
    "    traj_gt.set_coeffs(coeffs=coeffs_gt)\n",
    "    traj_gt.plot_pretty(times=times, color='black', ax=ax, label='ground truth fitted', linestyle=':')\n",
    "\n",
    "    ax.plot(full_df.px, full_df.py, color='black', label='ground truth')\n",
    "    ax.set_xlabel('x [m]')\n",
    "    ax.set_title('N={}'.format(n_measurements))\n",
    "\n",
    "    ax.set_xlim(*xlim)\n",
    "    ax.set_ylim(*ylim)\n",
    "\n",
    "legend = ax.legend(loc='lower right', ncol=3, facecolor='white', framealpha=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_measurements = 200\n",
    "sigmas = [0.1, 1, 2, 5, 10]\n",
    "fig, axs = plt.subplots(1, len(sigmas), sharex=True, sharey=True)\n",
    "fig.set_size_inches(3*len(sigmas), 5)\n",
    "\n",
    "np.random.seed(1)\n",
    "\n",
    "method = 'noise'\n",
    "k = 1\n",
    "for ax, sigma in zip(axs, sigmas):\n",
    "    #print(f'sigma {sigma}')\n",
    "    coeffs = np.empty([traj.dim, n_complexity, 0])\n",
    "    indices = np.random.choice(D.shape[0], n_measurements, replace=False)\n",
    "\n",
    "    D_small = D[indices, :]\n",
    "    times_small = np.array(times)[indices]\n",
    "    basis = traj.get_basis(times=times_small)\n",
    "    \n",
    "    coeffs_init = init_lm(coeffs_gt, method=method, sigma=sigma)\n",
    "    \n",
    "    x0 = coeffs_init.reshape((-1,))\n",
    "    #Crand = least_squares_lm(D_small, anchors, basis, x0, cost='squared')\n",
    "    #Crand = least_squares_lm(D_small, anchors, basis, x0, cost='squared', jacobian=True)\n",
    "    Crand = least_squares_lm(D_small, anchors, basis, x0, cost='simple')\n",
    "    \n",
    "    Chat = trajectory_recovery(D_small, anchors, basis, weighted=True)\n",
    "    \n",
    "    \n",
    "    # plotting\n",
    "    ax.set_title(f'sigma={sigma}')\n",
    "    traj.set_coeffs(coeffs=coeffs_init)\n",
    "    traj.plot_pretty(times=times, color=f'C{k}', ax=ax, label=method+' init', linestyle='-')\n",
    "    traj.set_coeffs(coeffs=Crand)\n",
    "    traj.plot_pretty(times=times, color=f'C{k+1}', ax=ax, label=method+' res', linestyle=':')\n",
    "    traj.set_coeffs(coeffs=Chat)\n",
    "    traj.plot_pretty(times=times, color=f'C{k+2}', ax=ax, label='ours', linestyle='-')\n",
    "    \n",
    "    traj.set_coeffs(coeffs=coeffs_gt)\n",
    "    traj.plot_pretty(times=times, color='black', ax=ax, label='ground truth fitted', linestyle=':')\n",
    "    ax.plot(full_df.px, full_df.py, color='black', label='ground truth')\n",
    "\n",
    "ax.set_xlabel('x [m]')\n",
    "\n",
    "ax.set_xlim(*xlim)\n",
    "ax.set_ylim(*ylim)\n",
    "\n",
    "axs[0].set_ylabel('y [m]')\n",
    "legend = ax.legend(loc='lower right', ncol=3, facecolor='white', framealpha=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterative algorithms\n",
    "\n",
    "In this section, we apply our trajectory estimation iteratively: either using a constant time window (Averaging algortihm) or building up and refining the trajectory as we go (Build up algorithm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "period_it = 10\n",
    "if dataname == 'uah1':\n",
    "    # for iterative.\n",
    "    n_complexity_it = 2\n",
    "    model_it = 'polynomial'\n",
    "    t_window_it = 80\n",
    "elif dataname == 'Plaza1':\n",
    "    # for iterative.\n",
    "    n_complexity_it = 3\n",
    "    model_it = 'full_bandlimited'\n",
    "    period_it = 40\n",
    "    t_window_it = 20\n",
    "elif dataname == 'Plaza2':\n",
    "    # for iterative.\n",
    "    n_complexity_it = 3\n",
    "    model_it = 'bandlimited'\n",
    "    period_it = 40\n",
    "    t_window_it = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj_it = traj.copy()\n",
    "traj_it.set_n_complexity(n_complexity_it)\n",
    "traj_it.model = model_it\n",
    "traj_it.period = period_it\n",
    "basis = traj_it.get_basis(times=times)\n",
    "print('Using trajectory model: \\n model={}, K={}, period={}'.format(traj_it.model, traj_it.n_complexity, traj_it.period))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Averaging algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from iterative_algorithms import averaging_algorithm\n",
    "print('averaging with time window', t_window_it)\n",
    "C_list, t_list = averaging_algorithm(D, anchors[:2, :], basis, times, t_window=t_window_it)\n",
    "ax1 = plot_individual(C_list, t_list, traj_it)\n",
    "ax1.plot(ground_truth_pos.px, ground_truth_pos.py, color='black')\n",
    "result_df = get_smooth_points(C_list, t_list, traj_it)\n",
    "ax2 = plot_smooth(result_df)\n",
    "ax2.plot(ground_truth_pos.px, ground_truth_pos.py, color='black')\n",
    "[[ax.set_xlim(*xlim), ax.set_ylim(*ylim)] for ax in [ax1, ax2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Build up algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from iterative_algorithms import build_up_algorithm\n",
    "\n",
    "C_list, t_list = build_up_algorithm(D, anchors[:2, :], basis, times, eps=eps, verbose=False)\n",
    "ax1 = plot_individual(C_list, t_list, traj_it.copy())\n",
    "ax1.plot(ground_truth_pos.px, ground_truth_pos.py, color='black')\n",
    "\n",
    "result_df = get_smooth_points(C_list, t_list, traj_it)\n",
    "ax2 = plot_smooth(result_df)\n",
    "ax2.plot(ground_truth_pos.px, ground_truth_pos.py, color='black')\n",
    "[[ax.set_xlim(*xlim), ax.set_ylim(*ylim)] for ax in [ax1, ax2]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
