{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.io import loadmat\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "#%matplotlib notebook\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "plt.rcParams['figure.figsize'] = 7, 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Range-only datasets for localization \n",
    "\n",
    "### Download .mat files and save them in folder ./datasets/\n",
    "\n",
    "WiFi: http://www.robesafe.es/repository/UAHWiFiDataset/\n",
    "\n",
    "Landmower: https://github.com/gtrll/gpslam/tree/master/matlab/data\n",
    "\n",
    "\n",
    "File description (from WiFi website, seems to be similar for Landmower): \n",
    "```\n",
    "GT: Groundtruth path from Laser Scan matching\n",
    "Time (sec) \tX_pose (m) \tY_pose (m) \tHeading (rad)\n",
    "\n",
    "DR: Odometry Input (delta distance traveled and delta heading change)\n",
    "Time (sec) \tDelta Dist. Trav. (m) \tDelta Heading (rad)\n",
    "\n",
    "DR_PROC: Dead Reckoned Path from Odometry\n",
    "Time (sec) \tX_pose (m) \tY_pose (m) \tHeading (rad)\n",
    "\n",
    "TL: Surveyed Beacon Locations\n",
    "Time (sec) \tX_pose (m) \tY_pose (m)\n",
    "*NOTE by Frederike: above is probably ID instead of time.\n",
    "\n",
    "TD:\n",
    "Time (sec) \tSender / Antenna ID \tReceiver Node ID \tRange (m)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trajectory_creator import get_trajectory\n",
    "\n",
    "# Need to give different systems a name.\n",
    "gt_system_id = \"GT\"\n",
    "gt_anchor_id = \"GT\"\n",
    "range_system_id = \"Range\"\n",
    "\n",
    "filename = 'datasets/uah1.mat'; # fingers. works ok.\n",
    "t_window = 1.0\n",
    "min_time = 0\n",
    "max_time = 1000\n",
    "\n",
    "#filename = 'datasets/uah2.mat'; # square. does not work well.\n",
    "#min_time = 0\n",
    "#max_time = 1470\n",
    "#t_window = 1.0\n",
    "\n",
    "#filename = 'datasets/Plaza1.mat'; # zig zag. does not work super well.\n",
    "#min_time = 0 # first big circle\n",
    "#max_time = 200 # first big circle\n",
    "#min_time=510 # first loop\n",
    "#max_time=600 # first loop\n",
    "#min_time=0 # first loop\n",
    "#max_time=1000 # first loop\n",
    "#t_window = 0.5\n",
    "\n",
    "filename = 'datasets/Plaza2.mat' # triangle. works well.\n",
    "t_window = 0.1 \n",
    "max_time=100.3\n",
    "min_time=45.1\n",
    "\n",
    "traj = get_trajectory(filename)\n",
    "dataname = filename.split('/')[-1].split('.')[0]\n",
    "\n",
    "try: \n",
    "    result_dict = loadmat(filename)\n",
    "    print('read', filename)\n",
    "except FileNotFoundError:\n",
    "    print('ERROR: download the mat files as described in cell above.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate_dataset import format_anchors_df, format_data_df\n",
    "\n",
    "anchor_data = result_dict['TL']\n",
    "anchors_df = pd.DataFrame(columns=['anchor_id', 'system_id', 'px', 'py', 'pz'])\n",
    "anchor_ids = np.unique(anchor_data[:, 0])\n",
    "for i, anchor_id in enumerate(anchor_ids):\n",
    "    anchors_df.loc[i, 'anchor_id'] = anchor_id \n",
    "    anchors_df.loc[i, 'system_id'] = range_system_id\n",
    "    \n",
    "    # it is weird that there is more than one value for each anchor, it looks\n",
    "    # like this was a bug in the dataset. we make sure they are all\n",
    "    # the same and pick the first.\n",
    "    px_values = np.unique(anchor_data[anchor_data[:, 0]==anchor_id, 1])\n",
    "    py_values = np.unique(anchor_data[anchor_data[:, 0]==anchor_id, 2])\n",
    "    assert len(px_values) == 1\n",
    "    assert len(py_values) == 1\n",
    "    anchors_df.loc[i, 'px'] = px_values[0]\n",
    "    anchors_df.loc[i, 'py'] = py_values[0]\n",
    "    \n",
    "anchors_df = format_anchors_df(anchors_df, range_system_id=range_system_id, \n",
    "                               gt_system_id=gt_system_id)\n",
    "print('anchors: \\n', anchors_df)\n",
    "\n",
    "range_df = pd.DataFrame(columns=['timestamp', 'px', 'py', 'pz', 'distance', \n",
    "                            'system_id', 'anchor_id'])\n",
    "range_df.loc[:, 'distance'] = result_dict['TD'][:, 3]\n",
    "range_df.loc[:, 'timestamp'] = result_dict['TD'][:, 0]\n",
    "range_df.loc[:, 'anchor_id'] = result_dict['TD'][:, 2]\n",
    "range_df.loc[:, 'system_id'] = range_system_id \n",
    "\n",
    "gt_df = pd.DataFrame(columns=range_df.columns)\n",
    "gt_df.loc[:, 'px'] = result_dict['GT'][:, 1]\n",
    "gt_df.loc[:, 'py'] = result_dict['GT'][:, 2]\n",
    "gt_df.loc[:, 'timestamp'] = result_dict['GT'][:, 0]\n",
    "gt_df.loc[:, 'anchor_id'] = gt_anchor_id\n",
    "gt_df.loc[:, 'system_id'] = gt_system_id\n",
    "\n",
    "full_df = pd.concat([range_df, gt_df], ignore_index=True)\n",
    "full_df.sort_values('timestamp', inplace=True)\n",
    "full_df.reset_index(drop=True, inplace=True)\n",
    "full_df.loc[:, 'timestamp'] = full_df.timestamp -full_df.timestamp.min()\n",
    "print('time going from {:.1f} to {:.1f}'.format(full_df.timestamp.min(), full_df.timestamp.max()))\n",
    "new_df = full_df[(full_df.timestamp >= min_time) & (full_df.timestamp <= max_time)]\n",
    "print('warning: keeping {}/{}'.format(len(new_df), len(full_df)))\n",
    "full_df = new_df\n",
    "full_df = format_data_df(full_df, anchors_df, gt_system_id=gt_system_id, \n",
    "                         range_system_id=range_system_id)\n",
    "full_df.loc[:, 'timestamp'] = full_df.timestamp - full_df.timestamp.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2)\n",
    "sns.scatterplot(data=full_df, x='px', y='py', hue='timestamp', linewidth=0.0, \n",
    "                ax=axs[0])\n",
    "sns.scatterplot(data=full_df, x='timestamp', y='px', hue='timestamp', linewidth=0.0, \n",
    "                 ax=axs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate_dataset import add_gt_raw\n",
    "full_df = add_gt_raw(full_df, t_window=t_window, gt_system_id=gt_system_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2)\n",
    "range_df = full_df[full_df.system_id==range_system_id]\n",
    "sns.scatterplot(data=range_df, x='px', y='py', hue='timestamp', linewidth=0.0, \n",
    "                ax=axs[0])\n",
    "#sns.scatterplot(data=anchors_df, x='px', y='py', linewidth=0.0,  ax=axs[0], color='red')\n",
    "sns.scatterplot(data=range_df, x='timestamp', y='px', hue='timestamp', linewidth=0.0, \n",
    "                 ax=axs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate_dataset import apply_distance_gt\n",
    "full_df.loc[:, \"distance_gt\"] = full_df.apply(lambda row: apply_distance_gt(row, anchors_df, gt_system_id=gt_system_id), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "range_ids = full_df[full_df.system_id==range_system_id].anchor_id.unique()\n",
    "fig, axs = plt.subplots(len(range_ids), sharex=True)\n",
    "fig.set_size_inches(10, 10)\n",
    "for i, anchor_id in enumerate(sorted(range_ids)):\n",
    "    this_df = full_df[full_df.anchor_id==anchor_id]\n",
    "    axs[i].scatter(this_df.timestamp, this_df.distance, color='red', label='measured distance')\n",
    "    axs[i].scatter(this_df.timestamp, this_df.distance_gt, color='green', label='real distance')\n",
    "    axs[i].legend(loc='upper right')\n",
    "    axs[i].set_title('anchor {}'.format(anchor_id))\n",
    "    axs[i].set_ylabel('distance [m]')\n",
    "axs[i].set_xlabel('time [s]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.argsort(this_df.distance.values)\n",
    "distances = this_df.distance.values[indices]\n",
    "distances_gt = this_df.distance_gt.values[indices]\n",
    "errors = distances - distances_gt\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(5, 2)\n",
    "ax.scatter(distances_gt, errors, alpha=0.5)\n",
    "ax.set_xlabel('real distance [m]')\n",
    "ax.set_ylabel('error [m]')\n",
    "ax.set_title(dataname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate_dataset import get_length, compute_distance_matrix\n",
    "from trajectory import Trajectory\n",
    "\n",
    "# We want to find out the times of distance measurements, \n",
    "# and by how much we have moved.\n",
    "range_df = full_df[full_df.system_id==range_system_id]\n",
    "times = range_df.timestamp.unique()\n",
    "\n",
    "#chosen_distance = 'distance_gt'\n",
    "chosen_distance = 'distance'\n",
    "anchor_names = None # use all anchors.\n",
    "\n",
    "## Sometimes below changes the length of times and then things seem to crash. Need to find out why.\n",
    "D, times = compute_distance_matrix(full_df, anchors_df, \n",
    "                            anchor_names, times, chosen_distance)\n",
    "if np.sum(D>0) > D.shape[0]:\n",
    "    print('Warning: multiple measurements for some times!')\n",
    "    \n",
    "#plt.matshow(D[:10, :])\n",
    "print(D[:10, :])\n",
    "#plt.title('First 10 rows of D matrix')\n",
    "\n",
    "\n",
    "# Find one ground truth for each time when we have a distance\n",
    "# measurement. \n",
    "ground_truth_pos = full_df.loc[full_df.timestamp.isin(times), ['timestamp', 'px', 'py', 'pz']]\n",
    "ground_truth_pos = ground_truth_pos.astype(np.float32)\n",
    "ground_truth_pos = ground_truth_pos.groupby('timestamp').agg(np.nanmean)\n",
    "ground_truth_pos.reset_index(inplace=True)\n",
    "ground_truth_pos.fillna(method='ffill', inplace=True)\n",
    "\n",
    "# We need to translate the times to \"trajectory space\"\n",
    "lengths = get_length(ground_truth_pos)\n",
    "lengths[np.isnan(lengths)] = 0 # because beginning of lengths can still have nans.\n",
    "assert len(lengths) == D.shape[0], len(lengths)\n",
    "\n",
    "# Use only distances for which we have valid ground truth.\n",
    "mask = list(lengths>0) # keep first zero length but delete others.\n",
    "mask[0] = True\n",
    "print('original D', D.shape)\n",
    "D = D[mask, :]\n",
    "print('reduced D to', D.shape)\n",
    "\n",
    "times = np.array(times)[mask]\n",
    "lengths = lengths[mask]\n",
    "\n",
    "assert len(times) == D.shape[0], len(times)\n",
    "\n",
    "time_diffs = times[1:] - times[:-1]\n",
    "velocities = lengths[1:] / time_diffs\n",
    "plt.figure()\n",
    "plt.hist(velocities, bins=20)\n",
    "plt.title('velocity histogram')\n",
    "\n",
    "distances = np.cumsum(lengths)\n",
    "\n",
    "if anchor_names is None:\n",
    "    anchors = anchors_df.loc[:, ['px', 'py', 'pz']].values.astype(np.float32).T\n",
    "else:\n",
    "    raise NotImplementedError('need to implement this (not a big deal).')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from solvers import alternativePseudoInverse\n",
    "from plotting_tools import savefig\n",
    "\n",
    "list_complexities = [3, 5, 21, 51]\n",
    "for n_complexity in list_complexities:\n",
    "    traj.set_n_complexity(n_complexity)\n",
    "    \n",
    "    ###### IMPORTANT: of course, this does not work, because we  ######\n",
    "    # do not have the \"exact\" trajectory model. the best we can do ####\n",
    "    # is to use the actual times and hope they fit the model. I was ###\n",
    "    # dumb and it took me quite some time figuring this out. ##########\n",
    "    #times_corr,*_ = traj.get_times_from_distances(arbitrary_distances=distances, \n",
    "    #                                              time_steps=10000)\n",
    "    ###################################################################\n",
    "    \n",
    "    times_corr = times \n",
    "    basis = traj.get_basis(times=times_corr) \n",
    "    \n",
    "    Chat_weighted = alternativePseudoInverse(D, anchors[:2, :], basis, weighted=True)\n",
    "    Chat = alternativePseudoInverse(D, anchors[:2, :], basis, weighted=False)\n",
    "\n",
    "    traj_weighted = traj.copy()\n",
    "\n",
    "    traj.set_coeffs(coeffs=Chat)\n",
    "    traj_weighted.set_coeffs(coeffs=Chat_weighted)\n",
    "\n",
    "    ax = traj.plot(times=times_corr, color='green', label='non-weighted')\n",
    "    traj_weighted.plot(times=times_corr, color='blue', label='weighted', ax=ax)\n",
    "        \n",
    "    ax.plot(full_df.px, full_df.py, color='black', label='ground truth')\n",
    "    ax.set_xlabel('x [m]')\n",
    "    ax.set_ylabel('y [m]')\n",
    "    ax.set_title('K={}'.format(traj.n_complexity))\n",
    "    ax.legend()\n",
    "    ax.set_xlim(full_df.px.min(), full_df.px.max())\n",
    "    ax.set_ylim(full_df.py.min(), full_df.py.max())\n",
    "    savefig(plt.gcf(), 'results/{}/K{}.png'.format(dataname, n_complexity))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Averaging algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_individual(C_list, t_list, traj):\n",
    "    fig, ax = plt.subplots()\n",
    "    fig.set_size_inches(10, 7)\n",
    "\n",
    "    for Chat, t in zip(C_list, t_list):\n",
    "        traj_part.set_coeffs(coeffs=Chat)\n",
    "        if len(t) > 0:\n",
    "            traj_part.plot(ax=ax, times=t)\n",
    "            #traj_part.plot(ax=ax, times=t, label='{:.1f}'.format(t[0]))\n",
    "            \n",
    "    ax.set_xlim(*xlim)\n",
    "    ax.set_ylim(*ylim)\n",
    "        \n",
    "def plot_smooth(result_df):\n",
    "    fig, ax = plt.subplots()\n",
    "    fig.set_size_inches(10, 7)\n",
    "    #plt.scatter(result_df.px, result_df.py, s=1)\n",
    "    plt.scatter(result_df.px_median, result_df.py_median, s=2, color='red')\n",
    "    plt.plot(result_df.px_median, result_df.py_median, color='red')\n",
    "    \n",
    "    plt.plot(ground_truth_pos.px, ground_truth_pos.py, color='black')\n",
    "    ax.set_xlim(*xlim)\n",
    "    ax.set_ylim(*ylim)\n",
    "        \n",
    "def get_smooth_points(C_list, t_list, traj):\n",
    "    # Average the obtained trajectories\n",
    "    result_df = pd.DataFrame(columns=['px', 'py', 't'])\n",
    "    for Chat, t in zip(C_list, t_list):\n",
    "        traj.set_coeffs(coeffs=Chat)\n",
    "        positions = traj.get_sampling_points(times=t)\n",
    "        this_df = pd.DataFrame({\n",
    "            'px': positions[0, :],\n",
    "            'py': positions[1, :],\n",
    "            't': t })\n",
    "        result_df=pd.concat((this_df, result_df))\n",
    "    result_df.sort_values('t', inplace=True)\n",
    "    result_df.reindex()\n",
    "\n",
    "    import datetime\n",
    "    mean_window=10\n",
    "    datetimes = [datetime.datetime.fromtimestamp(t) for t in result_df.t]\n",
    "    result_df.index = [pd.Timestamp(datetime) for datetime in datetimes]\n",
    "    result_df.loc[:, 'px_median'] = result_df['px'].rolling('{}s'.format(mean_window), min_periods=1, center=False).median()\n",
    "    result_df.loc[:, 'py_median'] = result_df['py'].rolling('{}s'.format(mean_window), min_periods=1, center=False).median()\n",
    "\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "from iterative_algorithms import averaging_algorithm\n",
    "\n",
    "if dataname == 'Plaza1':\n",
    "    n_complexity = 3\n",
    "    traj.model = 'full_bandlimited'; traj.period=40;\n",
    "    t_window=20\n",
    "    xlim = -50, 10\n",
    "    ylim = -20, 75\n",
    "    \n",
    "if dataname == 'Plaza2':\n",
    "    n_complexity = 5\n",
    "    traj.model = 'full_bandlimited'; traj.period=40;\n",
    "    t_window=40\n",
    "    xlim = -80, 10\n",
    "    ylim = -20, 75\n",
    "    \n",
    "if dataname == 'uah1':\n",
    "    n_complexity = 2\n",
    "    traj.model = 'polynomial';\n",
    "    t_window = 80\n",
    "    xlim = 0, 50\n",
    "    ylim = -20, 20\n",
    "    \n",
    "if dataname == 'uah2':\n",
    "    n_complexity = 2\n",
    "    traj.model = 'polynomial';\n",
    "    t_window = 200\n",
    "    xlim = -50, 50\n",
    "    ylim = -10, 80\n",
    "\n",
    "traj.set_n_complexity(n_complexity)\n",
    "basis = traj.get_basis(times=times) \n",
    "\n",
    "C_list, t_list = averaging_algorithm(D, anchors[:2, :], basis, times, \n",
    "                                     t_window=t_window)\n",
    "traj_part = traj.copy()\n",
    "        \n",
    "plot_individual(C_list, t_list, traj_part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = get_smooth_points(C_list, t_list, traj)\n",
    "plot_smooth(result_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build up algorithm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from iterative_algorithms import build_up_algorithm\n",
    "\n",
    "if dataname == 'Plaza1':\n",
    "    eps = 0.5\n",
    "if dataname == 'Plaza2':\n",
    "    eps = 0.2\n",
    "elif dataname == 'uah1':\n",
    "    eps = 2.0\n",
    "elif dataname == 'uah2':\n",
    "    eps = 1.0\n",
    "\n",
    "C_list, t_list = build_up_algorithm(D, anchors[:2, :], basis, times_corr, eps=eps, verbose=False)\n",
    "\n",
    "plot_individual(C_list, t_list, traj)\n",
    "\n",
    "result_df = get_smooth_points(C_list, t_list, traj)\n",
    "plot_smooth(result_df)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#  Below is not working yet.\n",
    "from fit_curve import fit_trajectory\n",
    "positions = ground_truth_pos.loc[:, ['px', 'py']].astype(np.float32).values.T\n",
    "plt.figure()\n",
    "plt.scatter(positions[0, :], positions[1, :])\n",
    "\n",
    "C, times = fit_trajectory(traj, positions, max_iter=10)\n",
    "traj_fitted = traj.copy()\n",
    "traj_fitted.set_coeffs(coeffs=C)\n",
    "traj_fitted.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
