{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as tck\n",
    "import hypothesis as h\n",
    "from plotting_tools import make_dirs_safe\n",
    "import time\n",
    "plt.rcParams['figure.figsize'] = 10, 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of the rank of the constrain matrix\n",
    "\n",
    "In this notebook we use a little rearanged definitions of the left and right parts of matrix:\n",
    "\n",
    "Let us write $\\pmb{f_n}^\\top$ as $[1\\ \\pmb{g_n}^\\top]^\\top$, and similarly\n",
    "$\\tilde{\\pmb{a}}_m^\\top = [\\pmb{a_m}^\\top 1]^\\top$. We can then \n",
    "write the whole constraint vector as:\n",
    "$$\\begin{bmatrix}\n",
    "\\text{vect}(\\tilde{\\pmb{a}}_m\\pmb{f}_n^\\top)^\\top & \\text{vect}( \n",
    "\\pmb{g_n} \\pmb{f_n}^\\top)^\\top\n",
    "\\end{bmatrix}$$\n",
    "Then we have the needed constrains on the left, and constrains added due to the \n",
    "regularisation on the right.\n",
    "From the Lemmas from the paper we know that we can write:\n",
    "$$\\text{vect}(\\pmb{f_n f_n^\\top}) = \\pmb{R} \\pmb{f_n^e},$$\n",
    "where $\\pmb{R}$ is some (sparse) matrix, and $\\pmb{f_n^e}$ is a vector \n",
    "similar in structure to $\\pmb{f_n}$, and can be written as a concatenation of  $\\pmb{f_n}$ and $\\pmb{f}_n^{r}$.\n",
    "This means we can write our full system of equations as:\n",
    "\\begin{align}\n",
    "b &=\n",
    "\\begin{bmatrix}\n",
    "\\text{vect}(\\pmb{a_m f_n}^\\top)^\\top & (\\pmb{f_n^e})^\\top\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "\\pmb{C} \\\\\n",
    "\\pmb{R^\\top L} \\\\\\end{bmatrix}\\\\\n",
    "\\end{align}\n",
    "Or using $\\tilde{\\pmb{a}}_m$:\n",
    "\\begin{align}\n",
    "b &=\n",
    "\\begin{bmatrix}\n",
    "\\text{vect}(\\tilde{\\pmb{a}}_m \\pmb{f}_n^\\top)^\\top & \\pmb{f}_n^{r\\top}\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "\\pmb{C} \\\\\n",
    "\\pmb{R}^\\top \\pmb{L} \\\\\\end{bmatrix}\n",
    "\\end{align}\n",
    "\n",
    "And so for us left hand side refers to $\\text{vect}(\\tilde{\\pmb{a}}_m \\pmb{f}_n^\\top)^\\top$ and right hand side refers to $\\pmb{f}_n^{r\\top}$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rank vs number of measurements\n",
    "I those experiments, the number of dimentions $D$, number of constrains $K$ and number of positions $N$ is fixed,\n",
    "and for several different ranks the number of measurements is increasted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_dimensions = 2\n",
    "n_constrains = 5\n",
    "n_positions = 20\n",
    "min_positions = 10\n",
    "n_repetitions = 100\n",
    "directory = \"results/ranks/\"\n",
    "\n",
    "key = \"_d{}_c{}_p{}\".format(n_dimensions, n_constrains, n_positions)\n",
    "\n",
    "frame = h.get_frame(n_constrains, n_positions)\n",
    "n_anchors_list = [n_dimensions + 1, 2*n_dimensions, 4*n_dimensions, 8*n_dimensions, 100*n_dimensions]\n",
    "measuremets_range = list(range(n_dimensions * n_constrains, (n_dimensions + 1) * min_positions + 1))\n",
    "\n",
    "ranks = np.zeros((len(measuremets_range), len(n_anchors_list), n_repetitions))\n",
    "for a_idx, n_anchors in enumerate(n_anchors_list):\n",
    "    anchors = h.get_anchors(n_anchors, n_dimensions)\n",
    "    for m_idx, n_measurements in enumerate(measuremets_range):\n",
    "        for r in range(n_repetitions):\n",
    "            idx_a, idx_f = h.random_indexes(n_anchors, n_positions, n_measurements)\n",
    "            constrains = h.get_left_submatrix(idx_a, idx_f, anchors, frame)\n",
    "            ranks[m_idx, a_idx, r] = np.linalg.matrix_rank(constrains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_rank = (n_dimensions + 1) * n_constrains\n",
    "stop = 3 * max_rank\n",
    "n_repetitions = ranks.shape[2]\n",
    "x = np.array(measuremets_range) / max_rank\n",
    "\n",
    "f, ax = plt.subplots()\n",
    "for a_idx, n_anchors in enumerate(n_anchors_list):\n",
    "    plt.plot(\n",
    "        x,\n",
    "        np.mean(ranks[:, a_idx, :], axis=1) / max_rank,\n",
    "        label=\"mean rank, {} anchors\".format(n_anchors),\n",
    "        color=\"C{}\".format(a_idx),\n",
    "        linestyle='dashed')\n",
    "    plt.step(\n",
    "        x,\n",
    "        np.sum(ranks[:, a_idx, :] >= max_rank, axis=1) / n_repetitions,\n",
    "        label=\"probability, {} anchors\".format(n_anchors),\n",
    "        color=\"C{}\".format(a_idx),\n",
    "        where='post')\n",
    "plt.xlabel(\"number of measurements\")\n",
    "plt.grid()\n",
    "ax.xaxis.set_major_formatter(tck.FormatStrFormatter('%g (D+1)K'))\n",
    "ax.xaxis.set_major_locator(tck.MultipleLocator(base=1))\n",
    "plt.legend()\n",
    "fname = directory + \"left_matrix_anchors\" + key + \".pdf\"\n",
    "make_dirs_safe(fname)\n",
    "plt.savefig(fname)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rank vs number of positions\n",
    "Here the number of dimentions $D$, the number of constrains $K$ and the total number of measrurements are fixed.\n",
    "In particular, the number of measurements is $(D+1)K$, and we increase total number of sampling positions along the trajectory. We can see drastically different behaviour for exactly $D+1$ anchors than for more than $D+1$ anchors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_dimensions = 2\n",
    "n_constrains = 5\n",
    "n_anchors = 3\n",
    "min_positions = 5\n",
    "n_repetitions = 100\n",
    "directory = \"results/ranks/\"\n",
    "\n",
    "n_anchors_list = [n_dimensions + 1, n_dimensions + 2, n_dimensions + 3, n_dimensions + 4, n_dimensions + 20]\n",
    "n_measurements = (n_dimensions + 1) * n_constrains\n",
    "n_positions_list = list(range(min_positions, 10*min_positions+1))\n",
    "\n",
    "key = \"_d{}_c{}_m{}\".format(n_dimensions, n_constrains, n_measurements)\n",
    "\n",
    "start = time.time()\n",
    "ranks = np.zeros((len(n_positions_list), len(n_anchors_list), n_repetitions))\n",
    "for a_idx, n_anchors in enumerate(n_anchors_list):\n",
    "    anchors = h.get_anchors(n_anchors, n_dimensions)\n",
    "    for p_idx, n_positions in enumerate(n_positions_list):\n",
    "        for r in range(n_repetitions):\n",
    "            frame = h.get_frame(n_constrains, n_positions)\n",
    "            idx_a, idx_f = h.random_indexes(n_anchors, n_positions, n_measurements)\n",
    "            constrains = h.get_left_submatrix(idx_a, idx_f, anchors, frame)\n",
    "            ranks[p_idx, a_idx, r] = np.linalg.matrix_rank(constrains)\n",
    "end = time.time()\n",
    "print(\"elapsed time: {:.2f}s\".format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_rank = (n_dimensions + 1) * n_constrains\n",
    "\n",
    "f, ax = plt.subplots()\n",
    "for idx, n_anchors in enumerate(n_anchors_list):\n",
    "    plt.plot(\n",
    "        n_positions_list,\n",
    "        np.mean(ranks[:, idx, :], axis=-1) / max_rank,\n",
    "        label=\"mean rank, {} anchors\".format(n_anchors),\n",
    "        color=\"C{}\".format(idx),\n",
    "        linestyle='dashed')\n",
    "    plt.step(\n",
    "        n_positions_list,\n",
    "        np.mean(ranks[:, idx, :] >= max_rank, axis=-1),\n",
    "        label=\"probability, {} anchors\".format(n_anchors),\n",
    "        color=\"C{}\".format(idx),\n",
    "        where='post')\n",
    "plt.xlabel(\"number of positions\")\n",
    "# plt.ylim(0)\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "fname = directory + \"left_matrix_points2\" + key + \".pdf\"\n",
    "make_dirs_safe(fname)\n",
    "plt.savefig(fname)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Theory vs experiments\n",
    "\n",
    "Comparison between theoretical and simulated probabilties for $D+1$ anchros. \n",
    "\n",
    "#### Theory\n",
    "For exactly $D+1$ anchors, each anchor is \n",
    "\"responsible\" for a direction. Indeed, if we change the frame to the basis \n",
    "defined by our anchors, it will change the coefficients $\\pmb{C}$ we want to \n",
    "recover, but won't change $\\pmb{f}_n$s. But then the constrain matrix will \n",
    "have a form:\n",
    "$$\\begin{bmatrix}\n",
    "\\pmb{f_{n_1}} & \\pmb{0} & \\pmb{0} \\\\\n",
    "\\pmb{0} & \\pmb{f_{n_2}} & \\pmb{0} \\\\\n",
    "\\pmb{0} & \\pmb{0} & \\pmb{f_{n_3}}\\\\\n",
    "\\pmb{f_{n_4}} & \\pmb{0} & \\pmb{0} \\\\\n",
    "\\pmb{0} & \\pmb{f_{n_5}} & \\pmb{0} \\\\\n",
    "\\vdots & \\vdots & \\vdots \\\\ \n",
    "\\pmb{0} & \\pmb{0} & \\pmb{f_{n_{(D+1)K}}}\\\\\n",
    "\\end{bmatrix},\n",
    "$$\n",
    "where $\\pmb{0}$ is a vector of zeros of length $K$. Then we can see that \n",
    "in order to diagonalise the matrix, we need at least $K$ different \n",
    "$\\pmb{f}_n$s for each $K$. Since $\\pmb{f_n}$s do not repeat for the \n",
    "same anchor, this is sufficient and necessary condition. \n",
    "\n",
    "We can then calculate what is the probability of such situation. Assume that  \n",
    "we have $R = (D+1)K$ measurements, $M = D+1$ anchors and $N$ possible \n",
    "$f_n$s. We can pick $(D+1)K$ measurements out of $(D+1)N$ in:\n",
    "$${(D+1)N}\\choose{(D+1)K}$$\n",
    "ways. On the other hand, there is:\n",
    "$${{N}\\choose{K}}^{D+1}$$\n",
    "ways choose the $K$ measurements corresponding to each anchor.\n",
    "So the probability of having the right number of measurements for each anchor \n",
    "is:\n",
    "$$\n",
    "P_{N} = {{{N}\\choose{K}}^{D+1}}\\bigg/ {{{(D+1)N}\\choose{(D+1)K}}}\n",
    "$$\n",
    "Note that for $N=K$ we just get $P_{K}=1$.\n",
    "\n",
    "Using approximation formulas from Wikipedia, get a limit for large $N$:\n",
    "\\begin{align*}\n",
    "P_{N\\rightarrow \\infty} &\\approx \\frac{\\sqrt{D+1}}{\\sqrt{2\\pi \n",
    "K}^{D}}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_dimensions = 2\n",
    "n_constrains = 5\n",
    "n_anchors = 3\n",
    "min_positions = 5\n",
    "n_repetitions = 1000\n",
    "directory = \"results/ranks/\"\n",
    "\n",
    "n_anchors_list = [n_dimensions + 1]\n",
    "n_measurements = (n_dimensions + 1) * n_constrains\n",
    "n_positions_list = list(range(n_constrains, 10*n_constrains))\n",
    "\n",
    "key = \"_d{}_c{}_m{}\".format(n_dimensions, n_constrains, n_measurements)\n",
    "\n",
    "start = time.time()\n",
    "ranks = np.zeros((len(n_positions_list), len(n_anchors_list), n_repetitions))\n",
    "for a_idx, n_anchors in enumerate(n_anchors_list):\n",
    "    anchors = h.get_anchors(n_anchors, n_dimensions)\n",
    "    for p_idx, n_positions in enumerate(n_positions_list):\n",
    "        for r in range(n_repetitions):\n",
    "            frame = h.get_frame(n_constrains, n_positions)\n",
    "            idx_a, idx_f = h.random_indexes(n_anchors, n_positions, n_measurements)\n",
    "            constrains = h.get_left_submatrix(idx_a, idx_f, anchors, frame)\n",
    "            ranks[p_idx, a_idx, r] = np.linalg.matrix_rank(constrains)\n",
    "end = time.time()\n",
    "print(\"elapsed time: {:.2f}s\".format(end - start))\n",
    "\n",
    "probabilities = [h.probability_few_anchors(n_dimensions, n_constrains, n) for n in n_positions_list]\n",
    "probabilities = np.array(probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_rank = (n_dimensions + 1) * n_constrains\n",
    "\n",
    "f, ax = plt.subplots()\n",
    "idx = 0\n",
    "n_anchors = n_anchors_list[idx]\n",
    "mean =  np.mean(ranks[:, idx, :] >= max_rank, axis=-1)\n",
    "std = np.std(ranks[:, idx, :] >= max_rank, axis=-1)\n",
    "limit = h.probability_few_anchors_limit(n_dimensions, n_constrains)\n",
    "\n",
    "plt.plot(\n",
    "    n_positions_list,\n",
    "    mean,\n",
    "#     where='post',\n",
    "    label=\"estimated probability\")\n",
    "ax.fill_between(\n",
    "    n_positions_list,\n",
    "    np.maximum(mean-std, 0),\n",
    "    mean+std,\n",
    "    alpha=0.2,\n",
    "    label=\"estimated +/- std\")\n",
    "plt.plot(\n",
    "    n_positions_list,\n",
    "    probabilities,\n",
    "#     where='post',\n",
    "    label=\"calculated probability\")\n",
    "std_true = np.sqrt(probabilities - probabilities ** 2)\n",
    "ax.fill_between(\n",
    "    n_positions_list,\n",
    "    np.maximum(probabilities - std_true, 0),\n",
    "    probabilities + std_true,\n",
    "    alpha=0.2,\n",
    "    label=\"calcualted +/- std\")\n",
    "ax.axhline(\n",
    "    limit,\n",
    "    linestyle=\"--\",\n",
    "    color=\"g\",\n",
    "    label=r\"limit for $positoins\\rightarrow \\infty$\")\n",
    "plt.xlabel(\"number of positions\")\n",
    "# plt.ylim(0)\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.savefig(directory + \"estimated_claculated_100\" + key + \".pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
